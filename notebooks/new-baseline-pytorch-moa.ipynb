{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import copy\n","import seaborn as sns\n","\n","from sklearn import preprocessing\n","from sklearn.metrics import log_loss\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import sys\n","sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n","# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# Read data\n","data_dir = '../data/'\n","train_features = pd.read_csv(data_dir + 'train_features.csv')\n","train_targets_scored = pd.read_csv(data_dir + 'train_targets_scored.csv')\n","train_targets_nonscored = pd.read_csv(data_dir + 'train_targets_nonscored.csv')\n","\n","test_features = pd.read_csv(data_dir + 'test_features.csv')\n","sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["# select Genes col and cells col\n","GENES = [col for col in train_features.columns if col.startswith('g-')]\n","CELLS = [col for col in train_features.columns if col.startswith('c-')]\n","target_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["# global seed for every envirment\n","global_random_seed = 42\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=global_random_seed)"]},{"cell_type":"markdown","metadata":{},"source":["# Remove outliers"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# normalize data, drop outliers beyond 4 times standard\n","train_ = train_features.copy()\n","drop_set = set()\n","for col in GENES:\n","    \n","    mean = train_[col].mean()\n","    std = train_[col].std()\n","\n","    std_r = mean + 4*std\n","    std_l = mean - 4*std\n","\n","    drop_set = drop_set | set(train_[col][(train_[col]>std_r) | (train_[col]<std_l)].index.values)\n","\n","train_features = train_features.drop(drop_set).reset_index(drop=True)\n","train_targets_scored = train_targets_scored.drop(drop_set).reset_index(drop=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["# PCA features + Existing features"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["# Because there are lots of genes expression and cols, some of them are highly correlated\n","# which means we can cut off some unnecessary features to make data cleaner\n","# GENES\n","n_comp = 50\n","\n","data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n","data2 = (PCA(n_components=n_comp, random_state=global_random_seed).fit_transform(data[GENES]))\n","# split the pca processed file back to train and test\n","train2 = data2[:train_features.shape[0]]\n","test2 = data2[-test_features.shape[0]:]\n","\n","# then use the pca sampled data to generate a new dataframe\n","train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n","test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n","# concat the PCA processed df back to original one\n","# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n","train_features = pd.concat((train_features, train2), axis=1)\n","test_features = pd.concat((test_features, test2), axis=1)"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["#CELLS\n","n_comp = 15\n","\n","data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n","data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n","\n","train2 = data2[:train_features.shape[0]]\n","test2 = data2[-test_features.shape[0]:]\n","\n","train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n","test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n","\n","# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n","train_features = pd.concat((train_features, train2), axis=1)\n","test_features = pd.concat((test_features, test2), axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["# feature Selection using Variance Encoding"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>cp_type</th>\n","      <th>cp_time</th>\n","      <th>cp_dose</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>...</th>\n","      <th>912</th>\n","      <th>913</th>\n","      <th>914</th>\n","      <th>915</th>\n","      <th>916</th>\n","      <th>917</th>\n","      <th>918</th>\n","      <th>919</th>\n","      <th>920</th>\n","      <th>921</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_0039a2ff9</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>-0.2924</td>\n","      <td>0.0985</td>\n","      <td>-0.5631</td>\n","      <td>-0.3963</td>\n","      <td>0.1672</td>\n","      <td>-0.8124</td>\n","      <td>...</td>\n","      <td>-1.286635</td>\n","      <td>-0.807944</td>\n","      <td>-0.254147</td>\n","      <td>-0.769551</td>\n","      <td>0.374694</td>\n","      <td>-0.943341</td>\n","      <td>-0.853739</td>\n","      <td>-1.020810</td>\n","      <td>1.268631</td>\n","      <td>-0.508160</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_005c3cb48</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>0.1088</td>\n","      <td>-0.0945</td>\n","      <td>-0.0345</td>\n","      <td>-0.0853</td>\n","      <td>-0.6953</td>\n","      <td>0.0164</td>\n","      <td>...</td>\n","      <td>-0.700414</td>\n","      <td>0.264050</td>\n","      <td>0.467550</td>\n","      <td>0.466465</td>\n","      <td>0.321766</td>\n","      <td>-0.096887</td>\n","      <td>-0.585788</td>\n","      <td>-0.442236</td>\n","      <td>1.458439</td>\n","      <td>-0.131257</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_00a6e782e</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.7053</td>\n","      <td>-0.2772</td>\n","      <td>1.0630</td>\n","      <td>0.6516</td>\n","      <td>0.0751</td>\n","      <td>1.2170</td>\n","      <td>...</td>\n","      <td>0.014457</td>\n","      <td>-0.824938</td>\n","      <td>-0.280325</td>\n","      <td>0.422267</td>\n","      <td>0.833339</td>\n","      <td>-0.207679</td>\n","      <td>0.315848</td>\n","      <td>0.091144</td>\n","      <td>0.867342</td>\n","      <td>0.119282</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_00cf304ae</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>-0.9906</td>\n","      <td>-0.0223</td>\n","      <td>-0.7852</td>\n","      <td>0.1550</td>\n","      <td>0.0439</td>\n","      <td>-0.2081</td>\n","      <td>...</td>\n","      <td>2.618133</td>\n","      <td>-0.930276</td>\n","      <td>0.359080</td>\n","      <td>-0.518467</td>\n","      <td>0.145251</td>\n","      <td>-0.821268</td>\n","      <td>-0.958771</td>\n","      <td>0.592624</td>\n","      <td>0.060834</td>\n","      <td>0.903672</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_00f08ca12</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>-0.0323</td>\n","      <td>-0.8249</td>\n","      <td>-0.2119</td>\n","      <td>0.0735</td>\n","      <td>0.0658</td>\n","      <td>0.3392</td>\n","      <td>...</td>\n","      <td>0.191623</td>\n","      <td>0.397117</td>\n","      <td>-1.023402</td>\n","      <td>-1.146402</td>\n","      <td>0.945452</td>\n","      <td>0.569545</td>\n","      <td>0.278772</td>\n","      <td>0.125129</td>\n","      <td>-0.341397</td>\n","      <td>0.228540</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1384</th>\n","      <td>id_ff34140bb</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>-0.0704</td>\n","      <td>-1.1450</td>\n","      <td>-0.0736</td>\n","      <td>0.1689</td>\n","      <td>-0.1952</td>\n","      <td>0.9004</td>\n","      <td>...</td>\n","      <td>0.863094</td>\n","      <td>0.530982</td>\n","      <td>-0.325180</td>\n","      <td>1.104800</td>\n","      <td>-1.140337</td>\n","      <td>-0.461557</td>\n","      <td>-0.384257</td>\n","      <td>-0.007216</td>\n","      <td>0.205978</td>\n","      <td>-0.096774</td>\n","    </tr>\n","    <tr>\n","      <th>1385</th>\n","      <td>id_ff678b430</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>0.2191</td>\n","      <td>-0.3436</td>\n","      <td>0.7492</td>\n","      <td>0.3498</td>\n","      <td>2.8270</td>\n","      <td>-1.0520</td>\n","      <td>...</td>\n","      <td>1.678875</td>\n","      <td>0.809328</td>\n","      <td>-1.036321</td>\n","      <td>-0.532753</td>\n","      <td>0.924138</td>\n","      <td>0.311458</td>\n","      <td>-0.897197</td>\n","      <td>-0.087098</td>\n","      <td>0.115241</td>\n","      <td>0.024159</td>\n","    </tr>\n","    <tr>\n","      <th>1386</th>\n","      <td>id_ff96bcd4d</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.8801</td>\n","      <td>-0.2296</td>\n","      <td>-0.7150</td>\n","      <td>0.5461</td>\n","      <td>0.5096</td>\n","      <td>-0.6187</td>\n","      <td>...</td>\n","      <td>-0.922724</td>\n","      <td>0.663234</td>\n","      <td>-0.067335</td>\n","      <td>0.504786</td>\n","      <td>-1.231724</td>\n","      <td>0.497414</td>\n","      <td>-0.095706</td>\n","      <td>0.154999</td>\n","      <td>-1.038228</td>\n","      <td>0.024232</td>\n","    </tr>\n","    <tr>\n","      <th>1387</th>\n","      <td>id_ffa27d492</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>0.3963</td>\n","      <td>-0.3586</td>\n","      <td>-0.7736</td>\n","      <td>-0.7709</td>\n","      <td>0.1802</td>\n","      <td>-0.3832</td>\n","      <td>...</td>\n","      <td>-0.491864</td>\n","      <td>0.492831</td>\n","      <td>0.490924</td>\n","      <td>-0.468890</td>\n","      <td>0.250088</td>\n","      <td>0.675397</td>\n","      <td>0.743152</td>\n","      <td>0.371395</td>\n","      <td>-0.186513</td>\n","      <td>-0.148246</td>\n","    </tr>\n","    <tr>\n","      <th>1388</th>\n","      <td>id_fff8c2444</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.1608</td>\n","      <td>-1.0500</td>\n","      <td>0.2551</td>\n","      <td>-0.2239</td>\n","      <td>-0.2431</td>\n","      <td>0.4256</td>\n","      <td>...</td>\n","      <td>-0.270847</td>\n","      <td>-0.846138</td>\n","      <td>0.826577</td>\n","      <td>-1.099105</td>\n","      <td>0.305108</td>\n","      <td>-0.092860</td>\n","      <td>0.297637</td>\n","      <td>-0.430337</td>\n","      <td>0.326416</td>\n","      <td>0.112372</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1389 rows × 926 columns</p>\n","</div>"],"text/plain":["            sig_id cp_type cp_time cp_dose       0       1       2       3   \n","0     id_0039a2ff9  trt_cp      48      D2 -0.2924  0.0985 -0.5631 -0.3963  \\\n","1     id_005c3cb48  trt_cp      48      D1  0.1088 -0.0945 -0.0345 -0.0853   \n","2     id_00a6e782e  trt_cp      48      D1 -0.7053 -0.2772  1.0630  0.6516   \n","3     id_00cf304ae  trt_cp      24      D2 -0.9906 -0.0223 -0.7852  0.1550   \n","4     id_00f08ca12  trt_cp      48      D2 -0.0323 -0.8249 -0.2119  0.0735   \n","...            ...     ...     ...     ...     ...     ...     ...     ...   \n","1384  id_ff34140bb  trt_cp      48      D2 -0.0704 -1.1450 -0.0736  0.1689   \n","1385  id_ff678b430  trt_cp      24      D1  0.2191 -0.3436  0.7492  0.3498   \n","1386  id_ff96bcd4d  trt_cp      48      D1 -0.8801 -0.2296 -0.7150  0.5461   \n","1387  id_ffa27d492  trt_cp      48      D2  0.3963 -0.3586 -0.7736 -0.7709   \n","1388  id_fff8c2444  trt_cp      72      D1  0.1608 -1.0500  0.2551 -0.2239   \n","\n","           4       5  ...       912       913       914       915       916   \n","0     0.1672 -0.8124  ... -1.286635 -0.807944 -0.254147 -0.769551  0.374694  \\\n","1    -0.6953  0.0164  ... -0.700414  0.264050  0.467550  0.466465  0.321766   \n","2     0.0751  1.2170  ...  0.014457 -0.824938 -0.280325  0.422267  0.833339   \n","3     0.0439 -0.2081  ...  2.618133 -0.930276  0.359080 -0.518467  0.145251   \n","4     0.0658  0.3392  ...  0.191623  0.397117 -1.023402 -1.146402  0.945452   \n","...      ...     ...  ...       ...       ...       ...       ...       ...   \n","1384 -0.1952  0.9004  ...  0.863094  0.530982 -0.325180  1.104800 -1.140337   \n","1385  2.8270 -1.0520  ...  1.678875  0.809328 -1.036321 -0.532753  0.924138   \n","1386  0.5096 -0.6187  ... -0.922724  0.663234 -0.067335  0.504786 -1.231724   \n","1387  0.1802 -0.3832  ... -0.491864  0.492831  0.490924 -0.468890  0.250088   \n","1388 -0.2431  0.4256  ... -0.270847 -0.846138  0.826577 -1.099105  0.305108   \n","\n","           917       918       919       920       921  \n","0    -0.943341 -0.853739 -1.020810  1.268631 -0.508160  \n","1    -0.096887 -0.585788 -0.442236  1.458439 -0.131257  \n","2    -0.207679  0.315848  0.091144  0.867342  0.119282  \n","3    -0.821268 -0.958771  0.592624  0.060834  0.903672  \n","4     0.569545  0.278772  0.125129 -0.341397  0.228540  \n","...        ...       ...       ...       ...       ...  \n","1384 -0.461557 -0.384257 -0.007216  0.205978 -0.096774  \n","1385  0.311458 -0.897197 -0.087098  0.115241  0.024159  \n","1386  0.497414 -0.095706  0.154999 -1.038228  0.024232  \n","1387  0.675397  0.743152  0.371395 -0.186513 -0.148246  \n","1388 -0.092860  0.297637 -0.430337  0.326416  0.112372  \n","\n","[1389 rows x 926 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_selection import VarianceThreshold\n","# use variance threshold to collect columns\n","# remove low variance columns and features\n","var_thresh = VarianceThreshold(threshold=0.5)\n","# data = train_features.append(test_features)\n","data = pd.concat([train_features, test_features], axis = 0)\n","data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n","\n","# \n","train_features_transformed = data_transformed[ : train_features.shape[0]]\n","test_features_transformed = data_transformed[-test_features.shape[0] : ]\n","\n","\n","train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n","                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n","\n","train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n","\n","\n","test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n","                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n","\n","test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n","\n","train_features"]},{"cell_type":"markdown","metadata":{},"source":["# Binning"]},{"cell_type":"code","execution_count":11,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# for col in GENES:\n","#     train.loc[:, f'{col}_bin'] = pd.cut(train[col], bins=3, labels=False)\n","#     test.loc[:, f'{col}_bin'] = pd.cut(test[col], bins=3, labels=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Distribution plots"]},{"cell_type":"code","execution_count":12,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# plt.figure(figsize=(16,16))\n","# sns.set_style(\"whitegrid\")\n","\n","# gene_choice = np.random.choice(len(GENES), 16)\n","# for i, col in enumerate(gene_choice):\n","#     plt.subplot(4, 4, i+1)\n","#     plt.hist(train_features.loc[:, GENES[col]],bins=100, color='orange')\n","#     plt.title(GENES[col])"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["train = train_features.merge(train_targets_scored, on='sig_id')\n","train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n","test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n","\n","train.drop(columns=['cp_type'], axis = 1, inplace=True)\n","test.drop(columns=['cp_type'], axis = 1, inplace=True)\n","\n","target = train[train_targets_scored.columns]"]},{"cell_type":"markdown","metadata":{},"source":["# CV folds"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>cp_time</th>\n","      <th>cp_dose</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>...</th>\n","      <th>trpv_agonist</th>\n","      <th>trpv_antagonist</th>\n","      <th>tubulin_inhibitor</th>\n","      <th>tyrosine_kinase_inhibitor</th>\n","      <th>ubiquitin_specific_protease_inhibitor</th>\n","      <th>vegfr_inhibitor</th>\n","      <th>vitamin_b</th>\n","      <th>vitamin_d_receptor_agonist</th>\n","      <th>wnt_inhibitor</th>\n","      <th>kfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_00cf304ae</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>-0.9906</td>\n","      <td>-0.0223</td>\n","      <td>-0.7852</td>\n","      <td>0.1550</td>\n","      <td>0.0439</td>\n","      <td>-0.2081</td>\n","      <td>0.0270</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_016f18b33</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.5924</td>\n","      <td>-0.3747</td>\n","      <td>-0.2318</td>\n","      <td>-0.0164</td>\n","      <td>-0.7001</td>\n","      <td>0.2946</td>\n","      <td>-1.4090</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_018fc6bfa</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>-0.0788</td>\n","      <td>0.2323</td>\n","      <td>1.1880</td>\n","      <td>0.1744</td>\n","      <td>0.4090</td>\n","      <td>0.0857</td>\n","      <td>-0.2272</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_019a1ab73</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.8460</td>\n","      <td>-1.1200</td>\n","      <td>0.0532</td>\n","      <td>1.3220</td>\n","      <td>0.0357</td>\n","      <td>1.6190</td>\n","      <td>-0.5884</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_02973bcb5</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>0.2723</td>\n","      <td>0.9656</td>\n","      <td>-0.6440</td>\n","      <td>0.5406</td>\n","      <td>1.3150</td>\n","      <td>1.4570</td>\n","      <td>0.5476</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>961</th>\n","      <td>id_ff34140bb</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>-0.0704</td>\n","      <td>-1.1450</td>\n","      <td>-0.0736</td>\n","      <td>0.1689</td>\n","      <td>-0.1952</td>\n","      <td>0.9004</td>\n","      <td>-1.3220</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>962</th>\n","      <td>id_ff678b430</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>0.2191</td>\n","      <td>-0.3436</td>\n","      <td>0.7492</td>\n","      <td>0.3498</td>\n","      <td>2.8270</td>\n","      <td>-1.0520</td>\n","      <td>0.2731</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>963</th>\n","      <td>id_ff96bcd4d</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.8801</td>\n","      <td>-0.2296</td>\n","      <td>-0.7150</td>\n","      <td>0.5461</td>\n","      <td>0.5096</td>\n","      <td>-0.6187</td>\n","      <td>-0.4340</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>964</th>\n","      <td>id_ffa27d492</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>0.3963</td>\n","      <td>-0.3586</td>\n","      <td>-0.7736</td>\n","      <td>-0.7709</td>\n","      <td>0.1802</td>\n","      <td>-0.3832</td>\n","      <td>-0.1220</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>965</th>\n","      <td>id_fff8c2444</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.1608</td>\n","      <td>-1.0500</td>\n","      <td>0.2551</td>\n","      <td>-0.2239</td>\n","      <td>-0.2431</td>\n","      <td>0.4256</td>\n","      <td>-0.1166</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>966 rows × 1132 columns</p>\n","</div>"],"text/plain":["           sig_id cp_time cp_dose       0       1       2       3       4   \n","0    id_00cf304ae      24      D2 -0.9906 -0.0223 -0.7852  0.1550  0.0439  \\\n","1    id_016f18b33      48      D1 -0.5924 -0.3747 -0.2318 -0.0164 -0.7001   \n","2    id_018fc6bfa      24      D1 -0.0788  0.2323  1.1880  0.1744  0.4090   \n","3    id_019a1ab73      48      D1 -0.8460 -1.1200  0.0532  1.3220  0.0357   \n","4    id_02973bcb5      48      D1  0.2723  0.9656 -0.6440  0.5406  1.3150   \n","..            ...     ...     ...     ...     ...     ...     ...     ...   \n","961  id_ff34140bb      48      D2 -0.0704 -1.1450 -0.0736  0.1689 -0.1952   \n","962  id_ff678b430      24      D1  0.2191 -0.3436  0.7492  0.3498  2.8270   \n","963  id_ff96bcd4d      48      D1 -0.8801 -0.2296 -0.7150  0.5461  0.5096   \n","964  id_ffa27d492      48      D2  0.3963 -0.3586 -0.7736 -0.7709  0.1802   \n","965  id_fff8c2444      72      D1  0.1608 -1.0500  0.2551 -0.2239 -0.2431   \n","\n","          5       6  ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor   \n","0   -0.2081  0.0270  ...             0                0                  0  \\\n","1    0.2946 -1.4090  ...             0                0                  0   \n","2    0.0857 -0.2272  ...             0                0                  0   \n","3    1.6190 -0.5884  ...             0                0                  0   \n","4    1.4570  0.5476  ...             0                0                  0   \n","..      ...     ...  ...           ...              ...                ...   \n","961  0.9004 -1.3220  ...             0                0                  0   \n","962 -1.0520  0.2731  ...             0                0                  0   \n","963 -0.6187 -0.4340  ...             0                0                  0   \n","964 -0.3832 -0.1220  ...             0                0                  0   \n","965  0.4256 -0.1166  ...             0                0                  0   \n","\n","     tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor   \n","0                            0                                      0  \\\n","1                            0                                      0   \n","2                            0                                      0   \n","3                            0                                      0   \n","4                            0                                      0   \n","..                         ...                                    ...   \n","961                          0                                      0   \n","962                          0                                      0   \n","963                          0                                      0   \n","964                          0                                      0   \n","965                          0                                      0   \n","\n","     vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor   \n","0                  0          0                           0              0  \\\n","1                  0          0                           0              0   \n","2                  0          0                           0              0   \n","3                  0          0                           0              0   \n","4                  0          0                           0              0   \n","..               ...        ...                         ...            ...   \n","961                0          0                           0              0   \n","962                0          0                           0              0   \n","963                0          0                           0              0   \n","964                0          0                           0              0   \n","965                0          0                           0              0   \n","\n","     kfold  \n","0        4  \n","1        2  \n","2        4  \n","3        0  \n","4        2  \n","..     ...  \n","961      3  \n","962      0  \n","963      4  \n","964      0  \n","965      3  \n","\n","[966 rows x 1132 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["folds = train.copy()\n","\n","mskf = MultilabelStratifiedKFold(n_splits=5)\n","\n","for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n","    folds.loc[v_idx, 'kfold'] = int(f)\n","\n","folds['kfold'] = folds['kfold'].astype(int)\n","folds"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(966, 1131)\n","(966, 1132)\n","(3624, 925)\n","(966, 207)\n","(3982, 207)\n"]}],"source":["print(train.shape)\n","print(folds.shape)\n","print(test.shape)\n","print(target.shape)\n","print(sample_submission.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Classes"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["class MoADataset:\n","    def __init__(self, features, targets):\n","        self.features = features\n","        self.targets = targets\n","        \n","    def __len__(self):\n","        return (self.features.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        dct = {\n","            'x' : torch.tensor(self.features[idx, :].astype(np.float32), dtype=torch.float),\n","            'y' : torch.tensor(self.targets[idx, :].astype(np.float32), dtype=torch.float)            \n","        }\n","        return dct\n","    \n","class TestDataset:\n","    def __init__(self, features):\n","        self.features = features\n","        \n","    def __len__(self):\n","        return (self.features.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        dct = {\n","            'x' : torch.tensor(self.features[idx, :].astype(np.float32), dtype=torch.float)\n","        }\n","        return dct\n","    "]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n","    model.train()\n","    final_loss = 0\n","    \n","    for data in dataloader:\n","        optimizer.zero_grad()\n","        inputs, targets = data['x'].to(device), data['y'].to(device)\n","#         print(inputs.shape)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        final_loss += loss.item()\n","        \n","    final_loss /= len(dataloader)\n","    \n","    return final_loss\n","\n","\n","def valid_fn(model, loss_fn, dataloader, device):\n","    model.eval()\n","    final_loss = 0\n","    valid_preds = []\n","    \n","    for data in dataloader:\n","        inputs, targets = data['x'].to(device), data['y'].to(device)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, targets)\n","        \n","        final_loss += loss.item()\n","        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n","        \n","    final_loss /= len(dataloader)\n","    valid_preds = np.concatenate(valid_preds)\n","    \n","    return final_loss, valid_preds\n","\n","def inference_fn(model, dataloader, device):\n","    model.eval()\n","    preds = []\n","    \n","    for data in dataloader:\n","        inputs = data['x'].to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(inputs)\n","        \n","        preds.append(outputs.sigmoid().detach().cpu().numpy())\n","        \n","    preds = np.concatenate(preds)\n","    \n","    return preds\n","   \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, num_features, num_targets, hidden_size):\n","        super(Model, self).__init__()\n","        self.batch_norm1 = nn.BatchNorm1d(num_features)\n","        self.dropout1 = nn.Dropout(0.2)\n","        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n","        \n","        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n","        \n","        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n","        self.dropout3 = nn.Dropout(0.5)\n","        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n","    \n","    def forward(self, x):\n","        x = self.batch_norm1(x)\n","        x = self.dropout1(x)\n","        x = F.relu(self.dense1(x))\n","        \n","        x = self.batch_norm2(x)\n","        x = self.dropout2(x)\n","        x = F.relu(self.dense2(x))\n","        \n","        x = self.batch_norm3(x)\n","        x = self.dropout3(x)\n","        x = self.dense3(x)\n","        \n","        return x\n","\n","class AdvModel(nn.Module):\n","    def __init__(self, num_features, num_targets):\n","        super(AdvModel, self).__init__()\n","        self.hidden_size = [1500, 1250, 1000, 750]\n","        self.dropout_value = [0.5, 0.35, 0.3, 0.25]\n","\n","        self.batch_norm1 = nn.BatchNorm1d(num_features)\n","        self.dense1 = nn.Linear(num_features, self.hidden_size[0])\n","        \n","        self.batch_norm2 = nn.BatchNorm1d(self.hidden_size[0])\n","        self.dropout2 = nn.Dropout(self.dropout_value[0])\n","        self.dense2 = nn.Linear(self.hidden_size[0], self.hidden_size[1])\n","\n","        self.batch_norm3 = nn.BatchNorm1d(self.hidden_size[1])\n","        self.dropout3 = nn.Dropout(self.dropout_value[1])\n","        self.dense3 = nn.Linear(self.hidden_size[1], self.hidden_size[2])\n","\n","        self.batch_norm4 = nn.BatchNorm1d(self.hidden_size[2])\n","        self.dropout4 = nn.Dropout(self.dropout_value[2])\n","        self.dense4 = nn.Linear(self.hidden_size[2], self.hidden_size[3])\n","\n","        self.batch_norm5 = nn.BatchNorm1d(self.hidden_size[3])\n","        self.dropout5 = nn.Dropout(self.dropout_value[3])\n","        self.dense5 = nn.utils.weight_norm(nn.Linear(self.hidden_size[3], num_targets))\n","    \n","    def forward(self, x):\n","        x = self.batch_norm1(x)\n","        x = F.leaky_relu(self.dense1(x))\n","        \n","        x = self.batch_norm2(x)\n","        x = self.dropout2(x)\n","        x = F.leaky_relu(self.dense2(x))\n","\n","        x = self.batch_norm3(x)\n","        x = self.dropout3(x)\n","        x = F.leaky_relu(self.dense3(x))\n","\n","        x = self.batch_norm4(x)\n","        x = self.dropout4(x)\n","        x = F.leaky_relu(self.dense4(x))\n","\n","        x = self.batch_norm5(x)\n","        x = self.dropout5(x)\n","        x = self.dense5(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing steps"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["def process_data(data):\n","    \n","    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n","#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n","#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n","\n","# --------------------- Normalize ---------------------\n","#     for col in GENES:\n","#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n","    \n","#     for col in CELLS:\n","#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n","    \n","#--------------------- Removing Skewness ---------------------\n","#     for col in GENES + CELLS:\n","#         if(abs(data[col].skew()) > 0.75):\n","            \n","#             if(data[col].skew() < 0): # neg-skewness\n","#                 data[col] = data[col].max() - data[col] + 1\n","#                 data[col] = np.sqrt(data[col])\n","            \n","#             else:\n","#                 data[col] = np.sqrt(data[col])\n","    \n","    return data"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["927"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n","feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n","len(feature_cols)"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["# HyperParameters\n","\n","DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n","EPOCHS = 25\n","BATCH_SIZE = 128\n","LEARNING_RATE = 1e-3\n","WEIGHT_DECAY = 1e-5\n","NFOLDS = 2\n","EARLY_STOPPING_STEPS = 10\n","EARLY_STOP = False\n","\n","num_features=len(feature_cols)\n","num_targets=len(target_cols)\n","hidden_size=1024\n"]},{"cell_type":"markdown","metadata":{},"source":["# Single fold training"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["def run_training(fold, seed, adv = False):\n","    \n","    seed_everything(seed)\n","    \n","    train = process_data(folds)\n","    test_ = process_data(test)\n","    \n","    trn_idx = train[train['kfold'] != fold].index\n","    val_idx = train[train['kfold'] == fold].index\n","    \n","    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n","    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n","    \n","    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n","    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n","    \n","    train_dataset = MoADataset(x_train, y_train)\n","    valid_dataset = MoADataset(x_valid, y_valid)\n","    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","    if adv:\n","        model = AdvModel(\n","            num_features=num_features,\n","            num_targets=num_targets,\n","        )\n","    else:\n","        model = Model(\n","            num_features=num_features,\n","            num_targets=num_targets,\n","            hidden_size=hidden_size,\n","        )\n","\n","    \n","    model.to(DEVICE)\n","    \n","    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n","                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n","    \n","    loss_fn = nn.BCEWithLogitsLoss()\n","    \n","    early_stopping_steps = EARLY_STOPPING_STEPS\n","    early_step = 0\n","    \n","    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n","    best_loss = np.inf\n","    \n","    for epoch in range(EPOCHS):\n","        \n","        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n","        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n","        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n","        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n","        \n","        if valid_loss < best_loss:\n","            \n","            best_loss = valid_loss\n","            oof[val_idx] = valid_preds\n","            if adv:\n","                torch.save(model.state_dict(), f\"Adv_FOLD{fold}_.pth\")\n","            else:\n","                torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n","        \n","        elif(EARLY_STOP == True):\n","            \n","            early_step += 1\n","            if (early_step >= early_stopping_steps):\n","                break\n","            \n","    \n","    #--------------------- PREDICTION---------------------\n","    x_test = test_[feature_cols].values\n","    testdataset = TestDataset(x_test)\n","    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","    if adv:\n","        model = AdvModel(\n","            num_features=num_features,\n","            num_targets=num_targets,\n","        )\n","        model.load_state_dict(torch.load(f\"Adv_FOLD{fold}_.pth\"))\n","    else:\n","        model = Model(\n","            num_features=num_features,\n","            num_targets=num_targets,\n","            hidden_size=hidden_size,\n","        )\n","        model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n","\n","    model.to(DEVICE)\n","    \n","    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n","    predictions = inference_fn(model, testloader, DEVICE)\n","    \n","    return oof, predictions\n"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["def run_k_fold(NFOLDS, seed):\n","    oof = np.zeros((len(train), len(target_cols)))\n","    predictions = np.zeros((len(test), len(target_cols)))\n","    \n","    for fold in range(NFOLDS):\n","        oof_, pred_ = run_training(fold, seed, adv = True)\n","        \n","        predictions += pred_ / NFOLDS\n","        oof += oof_\n","        \n","    return oof, predictions"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[{"ename":"TypeError","evalue":"super(type, obj): obj must be an instance or subtype of type","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(test), \u001b[38;5;28mlen\u001b[39m(target_cols)))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m SEED:\n\u001b[0;32m----> 9\u001b[0m     oof_, predictions_ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_k_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNFOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     oof \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m oof_ \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(SEED)\n\u001b[1;32m     11\u001b[0m     predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m predictions_ \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(SEED)\n","Cell \u001b[0;32mIn[29], line 6\u001b[0m, in \u001b[0;36mrun_k_fold\u001b[0;34m(NFOLDS, seed)\u001b[0m\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(test), \u001b[38;5;28mlen\u001b[39m(target_cols)))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NFOLDS):\n\u001b[0;32m----> 6\u001b[0m     oof_, pred_ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pred_ \u001b[38;5;241m/\u001b[39m NFOLDS\n\u001b[1;32m      9\u001b[0m     oof \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m oof_\n","Cell \u001b[0;32mIn[22], line 23\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(fold, seed, adv)\u001b[0m\n\u001b[1;32m     20\u001b[0m validloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(valid_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adv:\n\u001b[0;32m---> 23\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAdvModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     model \u001b[38;5;241m=\u001b[39m Model(\n\u001b[1;32m     29\u001b[0m         num_features\u001b[38;5;241m=\u001b[39mnum_features,\n\u001b[1;32m     30\u001b[0m         num_targets\u001b[38;5;241m=\u001b[39mnum_targets,\n\u001b[1;32m     31\u001b[0m         hidden_size\u001b[38;5;241m=\u001b[39mhidden_size,\n\u001b[1;32m     32\u001b[0m     )\n","Cell \u001b[0;32mIn[18], line 33\u001b[0m, in \u001b[0;36mAdvModel.__init__\u001b[0;34m(self, num_features, num_targets)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_features, num_targets):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1500\u001b[39m, \u001b[38;5;241m1250\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m750\u001b[39m]\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_value \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.35\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.25\u001b[39m]\n","\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"]}],"source":["# Averaging on multiple SEEDS\n","\n","SEED = [0, 1, 2, 3 ,4, 5]\n","oof = np.zeros((len(train), len(target_cols)))\n","predictions = np.zeros((len(test), len(target_cols)))\n","\n","for seed in SEED:\n","    \n","    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n","    oof += oof_ / len(SEED)\n","    predictions += predictions_ / len(SEED)\n","\n","train[target_cols] = oof\n","test[target_cols] = predictions\n"]},{"cell_type":"code","execution_count":64,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# test['atp-sensitive_potassium_channel_antagonist'] = 0.0\n","# test['erbb2_inhibitor'] = 0.0\n","\n","# train['atp-sensitive_potassium_channel_antagonist'] = 0.0\n","# train['erbb2_inhibitor'] = 0.0"]},{"cell_type":"code","execution_count":65,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>5-alpha_reductase_inhibitor</th>\n","      <th>11-beta-hsd1_inhibitor</th>\n","      <th>acat_inhibitor</th>\n","      <th>acetylcholine_receptor_agonist</th>\n","      <th>acetylcholine_receptor_antagonist</th>\n","      <th>acetylcholinesterase_inhibitor</th>\n","      <th>adenosine_receptor_agonist</th>\n","      <th>adenosine_receptor_antagonist</th>\n","      <th>adenylyl_cyclase_activator</th>\n","      <th>...</th>\n","      <th>tropomyosin_receptor_kinase_inhibitor</th>\n","      <th>trpv_agonist</th>\n","      <th>trpv_antagonist</th>\n","      <th>tubulin_inhibitor</th>\n","      <th>tyrosine_kinase_inhibitor</th>\n","      <th>ubiquitin_specific_protease_inhibitor</th>\n","      <th>vegfr_inhibitor</th>\n","      <th>vitamin_b</th>\n","      <th>vitamin_d_receptor_agonist</th>\n","      <th>wnt_inhibitor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>23809</th>\n","      <td>id_fffb1ceed</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23810</th>\n","      <td>id_fffb70c0c</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23811</th>\n","      <td>id_fffc1c3f4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23812</th>\n","      <td>id_fffcb9e7c</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23813</th>\n","      <td>id_ffffdd77b</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23814 rows × 207 columns</p>\n","</div>"],"text/plain":["             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor   \n","0      id_000644bb2                            0                       0  \\\n","1      id_000779bfc                            0                       0   \n","2      id_000a6266a                            0                       0   \n","3      id_0015fd391                            0                       0   \n","4      id_001626bd3                            0                       0   \n","...             ...                          ...                     ...   \n","23809  id_fffb1ceed                            0                       0   \n","23810  id_fffb70c0c                            0                       0   \n","23811  id_fffc1c3f4                            0                       0   \n","23812  id_fffcb9e7c                            0                       0   \n","23813  id_ffffdd77b                            0                       0   \n","\n","       acat_inhibitor  acetylcholine_receptor_agonist   \n","0                   0                               0  \\\n","1                   0                               0   \n","2                   0                               0   \n","3                   0                               0   \n","4                   0                               0   \n","...               ...                             ...   \n","23809               0                               0   \n","23810               0                               0   \n","23811               0                               0   \n","23812               0                               0   \n","23813               0                               0   \n","\n","       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor   \n","0                                      0                               0  \\\n","1                                      0                               0   \n","2                                      0                               0   \n","3                                      0                               0   \n","4                                      0                               0   \n","...                                  ...                             ...   \n","23809                                  0                               0   \n","23810                                  0                               0   \n","23811                                  0                               0   \n","23812                                  0                               0   \n","23813                                  0                               0   \n","\n","       adenosine_receptor_agonist  adenosine_receptor_antagonist   \n","0                               0                              0  \\\n","1                               0                              0   \n","2                               0                              0   \n","3                               0                              0   \n","4                               0                              0   \n","...                           ...                            ...   \n","23809                           0                              0   \n","23810                           0                              0   \n","23811                           0                              0   \n","23812                           0                              0   \n","23813                           0                              0   \n","\n","       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor   \n","0                               0  ...                                      0  \\\n","1                               0  ...                                      0   \n","2                               0  ...                                      0   \n","3                               0  ...                                      0   \n","4                               0  ...                                      0   \n","...                           ...  ...                                    ...   \n","23809                           0  ...                                      0   \n","23810                           0  ...                                      0   \n","23811                           0  ...                                      0   \n","23812                           0  ...                                      0   \n","23813                           0  ...                                      0   \n","\n","       trpv_agonist  trpv_antagonist  tubulin_inhibitor   \n","0                 0                0                  0  \\\n","1                 0                0                  0   \n","2                 0                0                  0   \n","3                 0                0                  0   \n","4                 0                0                  0   \n","...             ...              ...                ...   \n","23809             0                0                  0   \n","23810             0                0                  0   \n","23811             0                0                  0   \n","23812             0                0                  0   \n","23813             0                0                  0   \n","\n","       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor   \n","0                              0                                      0  \\\n","1                              0                                      0   \n","2                              0                                      0   \n","3                              0                                      0   \n","4                              0                                      0   \n","...                          ...                                    ...   \n","23809                          0                                      0   \n","23810                          0                                      0   \n","23811                          0                                      0   \n","23812                          0                                      0   \n","23813                          0                                      0   \n","\n","       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n","0                    0          0                           0              0  \n","1                    0          0                           0              0  \n","2                    0          0                           0              0  \n","3                    0          0                           0              0  \n","4                    0          0                           0              0  \n","...                ...        ...                         ...            ...  \n","23809                0          0                           0              0  \n","23810                0          0                           0              0  \n","23811                0          0                           0              0  \n","23812                0          0                           0              0  \n","23813                0          0                           0              0  \n","\n","[23814 rows x 207 columns]"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["train_targets_scored"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(target_cols)\n"]},{"cell_type":"code","execution_count":66,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CV log_loss:  0.014652433808298056\n"]}],"source":["valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n","\n","\n","y_true = train_targets_scored[target_cols].values\n","y_pred = valid_results[target_cols].values\n","\n","score = 0\n","for i in range(len(target_cols)):\n","    score_ = log_loss(y_true[:, i], y_pred[:, i])\n","    score += score_ / target.shape[1]\n","    \n","print(\"CV log_loss: \", score)"]},{"cell_type":"code","execution_count":67,"metadata":{"trusted":true},"outputs":[],"source":["sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n","sub.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n"]}],"source":["# import torch\n","# import torch.nn as nn\n","# import torch.onnx as onnx\n","\n","# # 定义模型\n","# class Model(nn.Module):\n","#     def __init__(self, num_features, num_targets, hidden_size):\n","#         super(Model, self).__init__()\n","#         self.batch_norm1 = nn.BatchNorm1d(num_features)\n","#         self.dropout1 = nn.Dropout(0.2)\n","#         self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n","\n","#         self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n","#         self.dropout2 = nn.Dropout(0.5)\n","#         self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n","\n","#         self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n","#         self.dropout3 = nn.Dropout(0.5)\n","#         self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n","\n","#     def forward(self, x):\n","#         x = self.batch_norm1(x)\n","#         x = self.dropout1(x)\n","#         x = torch.relu(self.dense1(x))\n","\n","#         x = self.batch_norm2(x)\n","#         x = self.dropout2(x)\n","#         x = torch.relu(self.dense2(x))\n","\n","#         x = self.batch_norm3(x)\n","#         x = self.dropout3(x)\n","#         x = self.dense3(x)\n","\n","#         return x\n","\n","# # 创建模型实例\n","# model = Model(num_features=num_features, num_targets=num_targets, hidden_size=hidden_size)\n","\n","# # 创建一个示例输入\n","# x = torch.randn(21948, num_features)\n","\n","# # 导出模型为ONNX格式\n","# torch.onnx.export(model,  # 导出的模型\n","#                   x,  # 输入数据\n","#                   \"model.onnx\",  # 导出的文件路径\n","#                   )  # 显示详细信息\n"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting onnx\n","  Downloading onnx-1.14.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.20.2 in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (4.23.0)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (4.5.0)\n","Requirement already satisfied: numpy in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (1.24.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.14.0\n"]}],"source":["!pip install onnx"]},{"cell_type":"markdown","metadata":{},"source":["## Things that can improve your CV even further:\n","1. Increasing SEEDS\n","2. Feature Selection over GENES/CELLS columns\n","3. Model Hyperparameter Tuning\n","4. Removing Skewness from GENES/CELLS columns [Comment below if it helps]\n","5. PCA........................................[Comment below if it helps]\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.16 ('ann')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"c5aa68934cf576379d06986a60942effae75d2e29c28cc454c328232c9ed20eb"}}},"nbformat":4,"nbformat_minor":4}
