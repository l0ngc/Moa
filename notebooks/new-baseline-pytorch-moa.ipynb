{"cells":[{"cell_type":"code","execution_count":56,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import copy\n","import seaborn as sns\n","\n","from sklearn import preprocessing\n","from sklearn.metrics import log_loss\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import sys\n","sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n","# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n"]},{"cell_type":"code","execution_count":71,"metadata":{"trusted":true},"outputs":[],"source":["# Read data\n","data_dir = '../data/'\n","train_features = pd.read_csv(data_dir + 'train_features.csv')\n","train_targets_scored = pd.read_csv(data_dir + 'train_targets_scored.csv')\n","train_targets_nonscored = pd.read_csv(data_dir + 'train_targets_nonscored.csv')\n","\n","test_features = pd.read_csv(data_dir + 'test_features.csv')\n","sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')"]},{"cell_type":"code","execution_count":72,"metadata":{"trusted":true},"outputs":[],"source":["# select Genes col and cells col\n","GENES = [col for col in train_features.columns if col.startswith('g-')]\n","CELLS = [col for col in train_features.columns if col.startswith('c-')]\n","target_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()"]},{"cell_type":"code","execution_count":73,"metadata":{"trusted":true},"outputs":[],"source":["# global seed for every envirment\n","global_random_seed = 42\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=global_random_seed)"]},{"cell_type":"markdown","metadata":{},"source":["# Remove outliers"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["# normalize data, drop outliers beyond 4 times standard\n","train_ = train_features.copy()\n","drop_set = set()\n","for col in GENES:\n","    \n","    mean = train_[col].mean()\n","    std = train_[col].std()\n","\n","    std_r = mean + 4*std\n","    std_l = mean - 4*std\n","\n","    drop_set = drop_set | set(train_[col][(train_[col]>std_r) | (train_[col]<std_l)].index.values)\n","\n","train_features = train_features.drop(drop).reset_index(drop=True)\n","train_targets_scored = train_targets_scored.drop(drop).reset_index(drop=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["# PCA features + Existing features"]},{"cell_type":"code","execution_count":75,"metadata":{"trusted":true},"outputs":[],"source":["# Because there are lots of genes expression and cols, some of them are highly correlated\n","# which means we can cut off some unnecessary features to make data cleaner\n","# GENES\n","n_comp = 50\n","\n","data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n","data2 = (PCA(n_components=n_comp, random_state=global_random_seed).fit_transform(data[GENES]))\n","# split the pca processed file back to train and test\n","train2 = data2[:train_features.shape[0]]\n","test2 = data2[-test_features.shape[0]:]\n","\n","# then use the pca sampled data to generate a new dataframe\n","train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n","test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n","# concat the PCA processed df back to original one\n","# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n","train_features = pd.concat((train_features, train2), axis=1)\n","test_features = pd.concat((test_features, test2), axis=1)"]},{"cell_type":"code","execution_count":76,"metadata":{"trusted":true},"outputs":[],"source":["#CELLS\n","n_comp = 15\n","\n","data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n","data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n","\n","train2 = data2[:train_features.shape[0]]\n","test2 = data2[-test_features.shape[0]:]\n","\n","train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n","test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n","\n","# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n","train_features = pd.concat((train_features, train2), axis=1)\n","test_features = pd.concat((test_features, test2), axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["# feature Selection using Variance Encoding"]},{"cell_type":"code","execution_count":77,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>cp_type</th>\n","      <th>cp_time</th>\n","      <th>cp_dose</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>...</th>\n","      <th>915</th>\n","      <th>916</th>\n","      <th>917</th>\n","      <th>918</th>\n","      <th>919</th>\n","      <th>920</th>\n","      <th>921</th>\n","      <th>922</th>\n","      <th>923</th>\n","      <th>924</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>1.0620</td>\n","      <td>0.5577</td>\n","      <td>-0.2479</td>\n","      <td>-0.6208</td>\n","      <td>-0.1944</td>\n","      <td>-1.0120</td>\n","      <td>...</td>\n","      <td>-0.679115</td>\n","      <td>0.386335</td>\n","      <td>1.004409</td>\n","      <td>-0.249936</td>\n","      <td>0.883299</td>\n","      <td>0.610465</td>\n","      <td>-0.753061</td>\n","      <td>-0.671275</td>\n","      <td>0.067252</td>\n","      <td>-0.389763</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.0743</td>\n","      <td>0.4087</td>\n","      <td>0.2991</td>\n","      <td>0.0604</td>\n","      <td>1.0190</td>\n","      <td>0.5207</td>\n","      <td>...</td>\n","      <td>0.180168</td>\n","      <td>0.594968</td>\n","      <td>-0.562946</td>\n","      <td>0.259693</td>\n","      <td>-0.329798</td>\n","      <td>0.814158</td>\n","      <td>-0.118183</td>\n","      <td>0.958425</td>\n","      <td>1.099968</td>\n","      <td>-0.033433</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>0.6280</td>\n","      <td>0.5817</td>\n","      <td>1.5540</td>\n","      <td>-0.0764</td>\n","      <td>-0.0323</td>\n","      <td>1.2390</td>\n","      <td>...</td>\n","      <td>0.026945</td>\n","      <td>0.757194</td>\n","      <td>-0.051018</td>\n","      <td>0.868632</td>\n","      <td>0.399917</td>\n","      <td>-0.354224</td>\n","      <td>0.001462</td>\n","      <td>0.375780</td>\n","      <td>-0.633219</td>\n","      <td>0.231283</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.5138</td>\n","      <td>-0.2491</td>\n","      <td>-0.2656</td>\n","      <td>0.5288</td>\n","      <td>4.0620</td>\n","      <td>-0.8095</td>\n","      <td>...</td>\n","      <td>0.765914</td>\n","      <td>0.473513</td>\n","      <td>-0.266450</td>\n","      <td>0.824174</td>\n","      <td>0.116938</td>\n","      <td>0.165857</td>\n","      <td>0.350874</td>\n","      <td>1.438046</td>\n","      <td>0.400377</td>\n","      <td>-1.213514</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>-0.3254</td>\n","      <td>-0.4009</td>\n","      <td>0.9700</td>\n","      <td>0.6919</td>\n","      <td>1.4180</td>\n","      <td>-0.8244</td>\n","      <td>...</td>\n","      <td>-0.121051</td>\n","      <td>-0.247922</td>\n","      <td>0.100196</td>\n","      <td>-0.022519</td>\n","      <td>0.368195</td>\n","      <td>-0.018785</td>\n","      <td>-0.225018</td>\n","      <td>0.358319</td>\n","      <td>-0.480647</td>\n","      <td>0.194421</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>23471</th>\n","      <td>id_fffb1ceed</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>0.1394</td>\n","      <td>-0.0636</td>\n","      <td>-0.1112</td>\n","      <td>-0.5080</td>\n","      <td>-0.4713</td>\n","      <td>0.7201</td>\n","      <td>...</td>\n","      <td>-0.209719</td>\n","      <td>0.773739</td>\n","      <td>-0.578295</td>\n","      <td>0.186360</td>\n","      <td>-0.251216</td>\n","      <td>-0.475677</td>\n","      <td>0.751856</td>\n","      <td>0.669870</td>\n","      <td>0.902451</td>\n","      <td>-1.225565</td>\n","    </tr>\n","    <tr>\n","      <th>23472</th>\n","      <td>id_fffb70c0c</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>-1.3260</td>\n","      <td>0.3478</td>\n","      <td>-0.3743</td>\n","      <td>0.9905</td>\n","      <td>-0.7178</td>\n","      <td>0.6621</td>\n","      <td>...</td>\n","      <td>-1.409792</td>\n","      <td>0.258293</td>\n","      <td>1.200588</td>\n","      <td>1.280937</td>\n","      <td>-0.853571</td>\n","      <td>-0.087748</td>\n","      <td>0.440373</td>\n","      <td>-0.286749</td>\n","      <td>0.614287</td>\n","      <td>-0.017665</td>\n","    </tr>\n","    <tr>\n","      <th>23473</th>\n","      <td>id_fffc1c3f4</td>\n","      <td>ctl_vehicle</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>0.3942</td>\n","      <td>0.3756</td>\n","      <td>0.3109</td>\n","      <td>-0.7389</td>\n","      <td>0.5505</td>\n","      <td>-0.0159</td>\n","      <td>...</td>\n","      <td>-0.486002</td>\n","      <td>0.044895</td>\n","      <td>0.257686</td>\n","      <td>0.097537</td>\n","      <td>0.500265</td>\n","      <td>-0.002098</td>\n","      <td>0.268270</td>\n","      <td>0.286804</td>\n","      <td>-0.005163</td>\n","      <td>0.001462</td>\n","    </tr>\n","    <tr>\n","      <th>23474</th>\n","      <td>id_fffcb9e7c</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>0.6660</td>\n","      <td>0.2324</td>\n","      <td>0.4392</td>\n","      <td>0.2044</td>\n","      <td>0.8531</td>\n","      <td>-0.0343</td>\n","      <td>...</td>\n","      <td>-1.003012</td>\n","      <td>0.127816</td>\n","      <td>-0.089046</td>\n","      <td>0.537621</td>\n","      <td>-0.363838</td>\n","      <td>0.877906</td>\n","      <td>-1.648234</td>\n","      <td>-0.096201</td>\n","      <td>-0.109356</td>\n","      <td>-1.233086</td>\n","    </tr>\n","    <tr>\n","      <th>23475</th>\n","      <td>id_ffffdd77b</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>-0.8598</td>\n","      <td>1.0240</td>\n","      <td>-0.1361</td>\n","      <td>0.7952</td>\n","      <td>-0.3611</td>\n","      <td>-3.6750</td>\n","      <td>...</td>\n","      <td>3.624209</td>\n","      <td>-0.720413</td>\n","      <td>0.168487</td>\n","      <td>-1.219211</td>\n","      <td>-4.795585</td>\n","      <td>-0.342343</td>\n","      <td>0.103018</td>\n","      <td>2.594063</td>\n","      <td>-0.523681</td>\n","      <td>4.511922</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23476 rows × 929 columns</p>\n","</div>"],"text/plain":["             sig_id      cp_type cp_time cp_dose       0       1       2   \n","0      id_000644bb2       trt_cp      24      D1  1.0620  0.5577 -0.2479  \\\n","1      id_000779bfc       trt_cp      72      D1  0.0743  0.4087  0.2991   \n","2      id_000a6266a       trt_cp      48      D1  0.6280  0.5817  1.5540   \n","3      id_0015fd391       trt_cp      48      D1 -0.5138 -0.2491 -0.2656   \n","4      id_001626bd3       trt_cp      72      D2 -0.3254 -0.4009  0.9700   \n","...             ...          ...     ...     ...     ...     ...     ...   \n","23471  id_fffb1ceed       trt_cp      24      D2  0.1394 -0.0636 -0.1112   \n","23472  id_fffb70c0c       trt_cp      24      D2 -1.3260  0.3478 -0.3743   \n","23473  id_fffc1c3f4  ctl_vehicle      48      D2  0.3942  0.3756  0.3109   \n","23474  id_fffcb9e7c       trt_cp      24      D1  0.6660  0.2324  0.4392   \n","23475  id_ffffdd77b       trt_cp      72      D1 -0.8598  1.0240 -0.1361   \n","\n","            3       4       5  ...       915       916       917       918   \n","0     -0.6208 -0.1944 -1.0120  ... -0.679115  0.386335  1.004409 -0.249936  \\\n","1      0.0604  1.0190  0.5207  ...  0.180168  0.594968 -0.562946  0.259693   \n","2     -0.0764 -0.0323  1.2390  ...  0.026945  0.757194 -0.051018  0.868632   \n","3      0.5288  4.0620 -0.8095  ...  0.765914  0.473513 -0.266450  0.824174   \n","4      0.6919  1.4180 -0.8244  ... -0.121051 -0.247922  0.100196 -0.022519   \n","...       ...     ...     ...  ...       ...       ...       ...       ...   \n","23471 -0.5080 -0.4713  0.7201  ... -0.209719  0.773739 -0.578295  0.186360   \n","23472  0.9905 -0.7178  0.6621  ... -1.409792  0.258293  1.200588  1.280937   \n","23473 -0.7389  0.5505 -0.0159  ... -0.486002  0.044895  0.257686  0.097537   \n","23474  0.2044  0.8531 -0.0343  ... -1.003012  0.127816 -0.089046  0.537621   \n","23475  0.7952 -0.3611 -3.6750  ...  3.624209 -0.720413  0.168487 -1.219211   \n","\n","            919       920       921       922       923       924  \n","0      0.883299  0.610465 -0.753061 -0.671275  0.067252 -0.389763  \n","1     -0.329798  0.814158 -0.118183  0.958425  1.099968 -0.033433  \n","2      0.399917 -0.354224  0.001462  0.375780 -0.633219  0.231283  \n","3      0.116938  0.165857  0.350874  1.438046  0.400377 -1.213514  \n","4      0.368195 -0.018785 -0.225018  0.358319 -0.480647  0.194421  \n","...         ...       ...       ...       ...       ...       ...  \n","23471 -0.251216 -0.475677  0.751856  0.669870  0.902451 -1.225565  \n","23472 -0.853571 -0.087748  0.440373 -0.286749  0.614287 -0.017665  \n","23473  0.500265 -0.002098  0.268270  0.286804 -0.005163  0.001462  \n","23474 -0.363838  0.877906 -1.648234 -0.096201 -0.109356 -1.233086  \n","23475 -4.795585 -0.342343  0.103018  2.594063 -0.523681  4.511922  \n","\n","[23476 rows x 929 columns]"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_selection import VarianceThreshold\n","# use variance threshold to collect columns\n","# remove low variance columns and features\n","var_thresh = VarianceThreshold(threshold=0.5)\n","# data = train_features.append(test_features)\n","data = pd.concat([train_features, test_features], axis = 0)\n","data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n","\n","# \n","train_features_transformed = data_transformed[ : train_features.shape[0]]\n","test_features_transformed = data_transformed[-test_features.shape[0] : ]\n","\n","\n","train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n","                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n","\n","train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n","\n","\n","test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n","                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n","\n","test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n","\n","train_features"]},{"cell_type":"markdown","metadata":{},"source":["# Binning"]},{"cell_type":"code","execution_count":78,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# for col in GENES:\n","#     train.loc[:, f'{col}_bin'] = pd.cut(train[col], bins=3, labels=False)\n","#     test.loc[:, f'{col}_bin'] = pd.cut(test[col], bins=3, labels=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Distribution plots"]},{"cell_type":"code","execution_count":79,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# plt.figure(figsize=(16,16))\n","# sns.set_style(\"whitegrid\")\n","\n","# gene_choice = np.random.choice(len(GENES), 16)\n","# for i, col in enumerate(gene_choice):\n","#     plt.subplot(4, 4, i+1)\n","#     plt.hist(train_features.loc[:, GENES[col]],bins=100, color='orange')\n","#     plt.title(GENES[col])"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["train = train_features.merge(train_targets_scored, on='sig_id')\n","train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n","test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n","\n","train.drop(columns=['cp_type'], axis = 1, inplace=True)\n","test.drop(columns=['cp_type'], axis = 1, inplace=True)\n","\n","target = train[train_targets_scored.columns]"]},{"cell_type":"markdown","metadata":{},"source":["# CV folds"]},{"cell_type":"code","execution_count":115,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>cp_type</th>\n","      <th>cp_time</th>\n","      <th>cp_dose</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>...</th>\n","      <th>trpv_agonist</th>\n","      <th>trpv_antagonist</th>\n","      <th>tubulin_inhibitor</th>\n","      <th>tyrosine_kinase_inhibitor</th>\n","      <th>ubiquitin_specific_protease_inhibitor</th>\n","      <th>vegfr_inhibitor</th>\n","      <th>vitamin_b</th>\n","      <th>vitamin_d_receptor_agonist</th>\n","      <th>wnt_inhibitor</th>\n","      <th>kfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>1.0</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>1.0620</td>\n","      <td>0.5577</td>\n","      <td>-0.2479</td>\n","      <td>-0.6208</td>\n","      <td>-0.1944</td>\n","      <td>-1.0120</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>1.0</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.0743</td>\n","      <td>0.4087</td>\n","      <td>0.2991</td>\n","      <td>0.0604</td>\n","      <td>1.0190</td>\n","      <td>0.5207</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>1.0</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>0.6280</td>\n","      <td>0.5817</td>\n","      <td>1.5540</td>\n","      <td>-0.0764</td>\n","      <td>-0.0323</td>\n","      <td>1.2390</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>1.0</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.5138</td>\n","      <td>-0.2491</td>\n","      <td>-0.2656</td>\n","      <td>0.5288</td>\n","      <td>4.0620</td>\n","      <td>-0.8095</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>1.0</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>-0.3254</td>\n","      <td>-0.4009</td>\n","      <td>0.9700</td>\n","      <td>0.6919</td>\n","      <td>1.4180</td>\n","      <td>-0.8244</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21605</th>\n","      <td>id_fff8c2444</td>\n","      <td>1.0</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.1608</td>\n","      <td>-1.0500</td>\n","      <td>0.2551</td>\n","      <td>-0.2239</td>\n","      <td>-0.2431</td>\n","      <td>0.4256</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21606</th>\n","      <td>id_fffb1ceed</td>\n","      <td>1.0</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>0.1394</td>\n","      <td>-0.0636</td>\n","      <td>-0.1112</td>\n","      <td>-0.5080</td>\n","      <td>-0.4713</td>\n","      <td>0.7201</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>21607</th>\n","      <td>id_fffb70c0c</td>\n","      <td>1.0</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>-1.3260</td>\n","      <td>0.3478</td>\n","      <td>-0.3743</td>\n","      <td>0.9905</td>\n","      <td>-0.7178</td>\n","      <td>0.6621</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21608</th>\n","      <td>id_fffcb9e7c</td>\n","      <td>1.0</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>0.6660</td>\n","      <td>0.2324</td>\n","      <td>0.4392</td>\n","      <td>0.2044</td>\n","      <td>0.8531</td>\n","      <td>-0.0343</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>21609</th>\n","      <td>id_ffffdd77b</td>\n","      <td>1.0</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>-0.8598</td>\n","      <td>1.0240</td>\n","      <td>-0.1361</td>\n","      <td>0.7952</td>\n","      <td>-0.3611</td>\n","      <td>-3.6750</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21610 rows × 1136 columns</p>\n","</div>"],"text/plain":["             sig_id  cp_type cp_time cp_dose       0       1       2       3   \n","0      id_000644bb2      1.0      24      D1  1.0620  0.5577 -0.2479 -0.6208  \\\n","1      id_000779bfc      1.0      72      D1  0.0743  0.4087  0.2991  0.0604   \n","2      id_000a6266a      1.0      48      D1  0.6280  0.5817  1.5540 -0.0764   \n","3      id_0015fd391      1.0      48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n","4      id_001626bd3      1.0      72      D2 -0.3254 -0.4009  0.9700  0.6919   \n","...             ...      ...     ...     ...     ...     ...     ...     ...   \n","21605  id_fff8c2444      1.0      72      D1  0.1608 -1.0500  0.2551 -0.2239   \n","21606  id_fffb1ceed      1.0      24      D2  0.1394 -0.0636 -0.1112 -0.5080   \n","21607  id_fffb70c0c      1.0      24      D2 -1.3260  0.3478 -0.3743  0.9905   \n","21608  id_fffcb9e7c      1.0      24      D1  0.6660  0.2324  0.4392  0.2044   \n","21609  id_ffffdd77b      1.0      72      D1 -0.8598  1.0240 -0.1361  0.7952   \n","\n","            4       5  ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor   \n","0     -0.1944 -1.0120  ...             0                0                  0  \\\n","1      1.0190  0.5207  ...             0                0                  0   \n","2     -0.0323  1.2390  ...             0                0                  0   \n","3      4.0620 -0.8095  ...             0                0                  0   \n","4      1.4180 -0.8244  ...             0                0                  0   \n","...       ...     ...  ...           ...              ...                ...   \n","21605 -0.2431  0.4256  ...             0                0                  0   \n","21606 -0.4713  0.7201  ...             0                0                  0   \n","21607 -0.7178  0.6621  ...             0                0                  0   \n","21608  0.8531 -0.0343  ...             0                0                  0   \n","21609 -0.3611 -3.6750  ...             0                0                  0   \n","\n","       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor   \n","0                              0                                      0  \\\n","1                              0                                      0   \n","2                              0                                      0   \n","3                              0                                      0   \n","4                              0                                      0   \n","...                          ...                                    ...   \n","21605                          0                                      0   \n","21606                          0                                      0   \n","21607                          0                                      0   \n","21608                          0                                      0   \n","21609                          0                                      0   \n","\n","       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor   \n","0                    0          0                           0              0  \\\n","1                    0          0                           0              0   \n","2                    0          0                           0              0   \n","3                    0          0                           0              0   \n","4                    0          0                           0              0   \n","...                ...        ...                         ...            ...   \n","21605                0          0                           0              0   \n","21606                0          0                           0              0   \n","21607                0          0                           0              0   \n","21608                0          0                           0              0   \n","21609                0          0                           0              0   \n","\n","       kfold  \n","0          1  \n","1          1  \n","2          1  \n","3          1  \n","4          3  \n","...      ...  \n","21605      1  \n","21606      4  \n","21607      0  \n","21608      3  \n","21609      1  \n","\n","[21610 rows x 1136 columns]"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["folds = train.copy()\n","\n","mskf = MultilabelStratifiedKFold(n_splits=5)\n","\n","for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n","    folds.loc[v_idx, 'kfold'] = int(f)\n","\n","folds['kfold'] = folds['kfold'].astype(int)\n","folds"]},{"cell_type":"code","execution_count":83,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(21610, 1135)\n","(21610, 1136)\n","(3624, 929)\n","(21610, 207)\n","(3982, 207)\n"]}],"source":["print(train.shape)\n","print(folds.shape)\n","print(test.shape)\n","print(target.shape)\n","print(sample_submission.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Classes"]},{"cell_type":"code","execution_count":116,"metadata":{"trusted":true},"outputs":[],"source":["class MoADataset:\n","    def __init__(self, features, targets):\n","        self.features = features\n","        self.targets = targets\n","        \n","    def __len__(self):\n","        return (self.features.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        dct = {\n","            'x' : torch.tensor(self.features[idx, :].astype(np.float32), dtype=torch.float),\n","            'y' : torch.tensor(self.targets[idx, :].astype(np.float32), dtype=torch.float)            \n","        }\n","        return dct\n","    \n","class TestDataset:\n","    def __init__(self, features):\n","        self.features = features\n","        \n","    def __len__(self):\n","        return (self.features.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        dct = {\n","            'x' : torch.tensor(self.features[idx, :].astype(np.float32), dtype=torch.float)\n","        }\n","        return dct\n","    "]},{"cell_type":"code","execution_count":117,"metadata":{"trusted":true},"outputs":[],"source":["def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n","    model.train()\n","    final_loss = 0\n","    \n","    for data in dataloader:\n","        optimizer.zero_grad()\n","        inputs, targets = data['x'].to(device), data['y'].to(device)\n","#         print(inputs.shape)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        final_loss += loss.item()\n","        \n","    final_loss /= len(dataloader)\n","    \n","    return final_loss\n","\n","\n","def valid_fn(model, loss_fn, dataloader, device):\n","    model.eval()\n","    final_loss = 0\n","    valid_preds = []\n","    \n","    for data in dataloader:\n","        inputs, targets = data['x'].to(device), data['y'].to(device)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, targets)\n","        \n","        final_loss += loss.item()\n","        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n","        \n","    final_loss /= len(dataloader)\n","    valid_preds = np.concatenate(valid_preds)\n","    \n","    return final_loss, valid_preds\n","\n","def inference_fn(model, dataloader, device):\n","    model.eval()\n","    preds = []\n","    \n","    for data in dataloader:\n","        inputs = data['x'].to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(inputs)\n","        \n","        preds.append(outputs.sigmoid().detach().cpu().numpy())\n","        \n","    preds = np.concatenate(preds)\n","    \n","    return preds\n","   \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":118,"metadata":{"trusted":true},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, num_features, num_targets, hidden_size):\n","        super(Model, self).__init__()\n","        self.batch_norm1 = nn.BatchNorm1d(num_features)\n","        self.dropout1 = nn.Dropout(0.2)\n","        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n","        \n","        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n","        \n","        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n","        self.dropout3 = nn.Dropout(0.5)\n","        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n","    \n","    def forward(self, x):\n","        x = self.batch_norm1(x)\n","        x = self.dropout1(x)\n","        x = F.relu(self.dense1(x))\n","        \n","        x = self.batch_norm2(x)\n","        x = self.dropout2(x)\n","        x = F.relu(self.dense2(x))\n","        \n","        x = self.batch_norm3(x)\n","        x = self.dropout3(x)\n","        x = self.dense3(x)\n","        \n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing steps"]},{"cell_type":"code","execution_count":119,"metadata":{"trusted":true},"outputs":[],"source":["def process_data(data):\n","    \n","    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n","#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n","#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n","\n","# --------------------- Normalize ---------------------\n","#     for col in GENES:\n","#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n","    \n","#     for col in CELLS:\n","#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n","    \n","#--------------------- Removing Skewness ---------------------\n","#     for col in GENES + CELLS:\n","#         if(abs(data[col].skew()) > 0.75):\n","            \n","#             if(data[col].skew() < 0): # neg-skewness\n","#                 data[col] = data[col].max() - data[col] + 1\n","#                 data[col] = np.sqrt(data[col])\n","            \n","#             else:\n","#                 data[col] = np.sqrt(data[col])\n","    \n","    return data"]},{"cell_type":"code","execution_count":120,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["931"]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n","feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n","len(feature_cols)"]},{"cell_type":"code","execution_count":121,"metadata":{"trusted":true},"outputs":[],"source":["# HyperParameters\n","\n","DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n","EPOCHS = 25\n","BATCH_SIZE = 128\n","LEARNING_RATE = 1e-3\n","WEIGHT_DECAY = 1e-5\n","NFOLDS = 5\n","EARLY_STOPPING_STEPS = 10\n","EARLY_STOP = False\n","\n","num_features=len(feature_cols)\n","num_targets=len(target_cols)\n","hidden_size=1024\n"]},{"cell_type":"markdown","metadata":{},"source":["# Single fold training"]},{"cell_type":"code","execution_count":122,"metadata":{"trusted":true},"outputs":[],"source":["def run_training(fold, seed):\n","    \n","    seed_everything(seed)\n","    \n","    train = process_data(folds)\n","    test_ = process_data(test)\n","    \n","    trn_idx = train[train['kfold'] != fold].index\n","    val_idx = train[train['kfold'] == fold].index\n","    \n","    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n","    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n","    \n","    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n","    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n","    \n","    train_dataset = MoADataset(x_train, y_train)\n","    valid_dataset = MoADataset(x_valid, y_valid)\n","    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","    model = Model(\n","        num_features=num_features,\n","        num_targets=num_targets,\n","        hidden_size=hidden_size,\n","    )\n","    \n","    model.to(DEVICE)\n","    \n","    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n","                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n","    \n","    loss_fn = nn.BCEWithLogitsLoss()\n","    \n","    early_stopping_steps = EARLY_STOPPING_STEPS\n","    early_step = 0\n","    \n","    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n","    best_loss = np.inf\n","    \n","    for epoch in range(EPOCHS):\n","        \n","        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n","        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n","        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n","        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n","        \n","        if valid_loss < best_loss:\n","            \n","            best_loss = valid_loss\n","            oof[val_idx] = valid_preds\n","            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n","        \n","        elif(EARLY_STOP == True):\n","            \n","            early_step += 1\n","            if (early_step >= early_stopping_steps):\n","                break\n","            \n","    \n","    #--------------------- PREDICTION---------------------\n","    x_test = test_[feature_cols].values\n","    testdataset = TestDataset(x_test)\n","    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","    model = Model(\n","        num_features=num_features,\n","        num_targets=num_targets,\n","        hidden_size=hidden_size,\n","    )\n","    \n","    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n","    model.to(DEVICE)\n","    \n","    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n","    predictions = inference_fn(model, testloader, DEVICE)\n","    \n","    return oof, predictions\n"]},{"cell_type":"code","execution_count":123,"metadata":{"trusted":true},"outputs":[],"source":["def run_k_fold(NFOLDS, seed):\n","    oof = np.zeros((len(train), len(target_cols)))\n","    predictions = np.zeros((len(test), len(target_cols)))\n","    \n","    for fold in range(NFOLDS):\n","        oof_, pred_ = run_training(fold, seed)\n","        \n","        predictions += pred_ / NFOLDS\n","        oof += oof_\n","        \n","    return oof, predictions"]},{"cell_type":"code","execution_count":125,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["FOLD: 0, EPOCH: 0, train_loss: 0.5474348454462254\n","FOLD: 0, EPOCH: 0, valid_loss: 0.03633869373623062\n","FOLD: 0, EPOCH: 1, train_loss: 0.02402336773572161\n","FOLD: 0, EPOCH: 1, valid_loss: 0.020837840569369933\n","FOLD: 0, EPOCH: 2, train_loss: 0.020409097758067006\n","FOLD: 0, EPOCH: 2, valid_loss: 0.018719121758990428\n","FOLD: 0, EPOCH: 3, train_loss: 0.018859581789001822\n","FOLD: 0, EPOCH: 3, valid_loss: 0.01818960373673369\n","FOLD: 0, EPOCH: 4, train_loss: 0.018250459579148275\n","FOLD: 0, EPOCH: 4, valid_loss: 0.017604676951818606\n","FOLD: 0, EPOCH: 5, train_loss: 0.017880307051681858\n","FOLD: 0, EPOCH: 5, valid_loss: 0.017412038383019322\n","FOLD: 0, EPOCH: 6, train_loss: 0.01758265103596975\n","FOLD: 0, EPOCH: 6, valid_loss: 0.017419910852742547\n","FOLD: 0, EPOCH: 7, train_loss: 0.017547568285782987\n","FOLD: 0, EPOCH: 7, valid_loss: 0.017393275081892225\n","FOLD: 0, EPOCH: 8, train_loss: 0.017557703951538047\n","FOLD: 0, EPOCH: 8, valid_loss: 0.017219771795413074\n","FOLD: 0, EPOCH: 9, train_loss: 0.01739840903182459\n","FOLD: 0, EPOCH: 9, valid_loss: 0.017168550396009404\n","FOLD: 0, EPOCH: 10, train_loss: 0.0173631177544046\n","FOLD: 0, EPOCH: 10, valid_loss: 0.0173032564275405\n","FOLD: 0, EPOCH: 11, train_loss: 0.017492194632616115\n","FOLD: 0, EPOCH: 11, valid_loss: 0.017106153153102186\n","FOLD: 0, EPOCH: 12, train_loss: 0.017322155318277722\n","FOLD: 0, EPOCH: 12, valid_loss: 0.017117672079407117\n","FOLD: 0, EPOCH: 13, train_loss: 0.01724027586854337\n","FOLD: 0, EPOCH: 13, valid_loss: 0.017077080604127225\n","FOLD: 0, EPOCH: 14, train_loss: 0.01719434139222893\n","FOLD: 0, EPOCH: 14, valid_loss: 0.017025713808834553\n","FOLD: 0, EPOCH: 15, train_loss: 0.017051774823545095\n","FOLD: 0, EPOCH: 15, valid_loss: 0.016930432223221836\n","FOLD: 0, EPOCH: 16, train_loss: 0.016835744636516797\n","FOLD: 0, EPOCH: 16, valid_loss: 0.016833994154106167\n","FOLD: 0, EPOCH: 17, train_loss: 0.0167902819264461\n","FOLD: 0, EPOCH: 17, valid_loss: 0.016706092337913373\n","FOLD: 0, EPOCH: 18, train_loss: 0.016548118704710815\n","FOLD: 0, EPOCH: 18, valid_loss: 0.016639188507243115\n","FOLD: 0, EPOCH: 19, train_loss: 0.016291147597846303\n","FOLD: 0, EPOCH: 19, valid_loss: 0.016468824435244587\n","FOLD: 0, EPOCH: 20, train_loss: 0.016114076229688877\n","FOLD: 0, EPOCH: 20, valid_loss: 0.016425186165553683\n","FOLD: 0, EPOCH: 21, train_loss: 0.015814418623716953\n","FOLD: 0, EPOCH: 21, valid_loss: 0.01634222888113821\n","FOLD: 0, EPOCH: 22, train_loss: 0.015564522911410998\n","FOLD: 0, EPOCH: 22, valid_loss: 0.016350549974424\n","FOLD: 0, EPOCH: 23, train_loss: 0.015348617953029187\n","FOLD: 0, EPOCH: 23, valid_loss: 0.016277516507269704\n","FOLD: 0, EPOCH: 24, train_loss: 0.015354848905083011\n","FOLD: 0, EPOCH: 24, valid_loss: 0.016313166768454453\n","FOLD: 1, EPOCH: 0, train_loss: 0.5473795626860332\n","FOLD: 1, EPOCH: 0, valid_loss: 0.0381363655495293\n","FOLD: 1, EPOCH: 1, train_loss: 0.02419179291738307\n","FOLD: 1, EPOCH: 1, valid_loss: 0.021500772741787574\n","FOLD: 1, EPOCH: 2, train_loss: 0.020432121449095363\n","FOLD: 1, EPOCH: 2, valid_loss: 0.018995555884697857\n","FOLD: 1, EPOCH: 3, train_loss: 0.01900191353086163\n","FOLD: 1, EPOCH: 3, valid_loss: 0.017977222526336416\n","FOLD: 1, EPOCH: 4, train_loss: 0.01850622132940985\n","FOLD: 1, EPOCH: 4, valid_loss: 0.017786940422785634\n","FOLD: 1, EPOCH: 5, train_loss: 0.01799322258653667\n","FOLD: 1, EPOCH: 5, valid_loss: 0.01749885202768971\n","FOLD: 1, EPOCH: 6, train_loss: 0.017768335049314535\n","FOLD: 1, EPOCH: 6, valid_loss: 0.01733657665660276\n","FOLD: 1, EPOCH: 7, train_loss: 0.017496229169945067\n","FOLD: 1, EPOCH: 7, valid_loss: 0.01744331863215741\n","FOLD: 1, EPOCH: 8, train_loss: 0.017478751265169942\n","FOLD: 1, EPOCH: 8, valid_loss: 0.017396238358581766\n","FOLD: 1, EPOCH: 9, train_loss: 0.0174718996277079\n","FOLD: 1, EPOCH: 9, valid_loss: 0.01732625127496088\n","FOLD: 1, EPOCH: 10, train_loss: 0.017507666126167512\n","FOLD: 1, EPOCH: 10, valid_loss: 0.01722041191533208\n","FOLD: 1, EPOCH: 11, train_loss: 0.01744802948087454\n","FOLD: 1, EPOCH: 11, valid_loss: 0.01717370392425972\n","FOLD: 1, EPOCH: 12, train_loss: 0.01732443136108272\n","FOLD: 1, EPOCH: 12, valid_loss: 0.01722695163505919\n","FOLD: 1, EPOCH: 13, train_loss: 0.017324638525571895\n","FOLD: 1, EPOCH: 13, valid_loss: 0.017151424770846087\n","FOLD: 1, EPOCH: 14, train_loss: 0.01712797162369551\n","FOLD: 1, EPOCH: 14, valid_loss: 0.01702723389162737\n","FOLD: 1, EPOCH: 15, train_loss: 0.017079889877041912\n","FOLD: 1, EPOCH: 15, valid_loss: 0.016854599830420577\n","FOLD: 1, EPOCH: 16, train_loss: 0.01692849715404651\n","FOLD: 1, EPOCH: 16, valid_loss: 0.016931697616682333\n","FOLD: 1, EPOCH: 17, train_loss: 0.01668740439858726\n","FOLD: 1, EPOCH: 17, valid_loss: 0.016765386797487736\n","FOLD: 1, EPOCH: 18, train_loss: 0.01649021975668695\n","FOLD: 1, EPOCH: 18, valid_loss: 0.01665758514119422\n","FOLD: 1, EPOCH: 19, train_loss: 0.01623951144489076\n","FOLD: 1, EPOCH: 19, valid_loss: 0.016571517595473456\n","FOLD: 1, EPOCH: 20, train_loss: 0.016027651864158755\n","FOLD: 1, EPOCH: 20, valid_loss: 0.016392374630360043\n","FOLD: 1, EPOCH: 21, train_loss: 0.01573587954044342\n","FOLD: 1, EPOCH: 21, valid_loss: 0.016313314848743817\n","FOLD: 1, EPOCH: 22, train_loss: 0.015455178060459302\n","FOLD: 1, EPOCH: 22, valid_loss: 0.016293453792219654\n","FOLD: 1, EPOCH: 23, train_loss: 0.015372193979975931\n","FOLD: 1, EPOCH: 23, valid_loss: 0.016251942635897326\n","FOLD: 1, EPOCH: 24, train_loss: 0.015292093082440688\n","FOLD: 1, EPOCH: 24, valid_loss: 0.01627940350376508\n","FOLD: 2, EPOCH: 0, train_loss: 0.5468845751465243\n","FOLD: 2, EPOCH: 0, valid_loss: 0.03908350954160971\n","FOLD: 2, EPOCH: 1, train_loss: 0.025045188458855536\n","FOLD: 2, EPOCH: 1, valid_loss: 0.022523706778883934\n","FOLD: 2, EPOCH: 2, train_loss: 0.02054179069476531\n","FOLD: 2, EPOCH: 2, valid_loss: 0.01940607723286923\n","FOLD: 2, EPOCH: 3, train_loss: 0.019403426305336112\n","FOLD: 2, EPOCH: 3, valid_loss: 0.018411779995350278\n","FOLD: 2, EPOCH: 4, train_loss: 0.01867655077812207\n","FOLD: 2, EPOCH: 4, valid_loss: 0.017983197453705704\n","FOLD: 2, EPOCH: 5, train_loss: 0.018297581166467246\n","FOLD: 2, EPOCH: 5, valid_loss: 0.01776823291883749\n","FOLD: 2, EPOCH: 6, train_loss: 0.017900270902935195\n","FOLD: 2, EPOCH: 6, valid_loss: 0.01747461170067682\n","FOLD: 2, EPOCH: 7, train_loss: 0.017807875575004694\n","FOLD: 2, EPOCH: 7, valid_loss: 0.017357120126047555\n","FOLD: 2, EPOCH: 8, train_loss: 0.01768504792605253\n","FOLD: 2, EPOCH: 8, valid_loss: 0.017286521875682997\n","FOLD: 2, EPOCH: 9, train_loss: 0.017549349179984453\n","FOLD: 2, EPOCH: 9, valid_loss: 0.017430510234964246\n","FOLD: 2, EPOCH: 10, train_loss: 0.01739307787433705\n","FOLD: 2, EPOCH: 10, valid_loss: 0.01718825479859815\n","FOLD: 2, EPOCH: 11, train_loss: 0.01740961927263176\n","FOLD: 2, EPOCH: 11, valid_loss: 0.01718321439864881\n","FOLD: 2, EPOCH: 12, train_loss: 0.017355803249622968\n","FOLD: 2, EPOCH: 12, valid_loss: 0.01705826216322534\n","FOLD: 2, EPOCH: 13, train_loss: 0.01715848599697518\n","FOLD: 2, EPOCH: 13, valid_loss: 0.017107123947318864\n","FOLD: 2, EPOCH: 14, train_loss: 0.01708941865602837\n","FOLD: 2, EPOCH: 14, valid_loss: 0.017004138433977085\n","FOLD: 2, EPOCH: 15, train_loss: 0.016957364675095853\n","FOLD: 2, EPOCH: 15, valid_loss: 0.016843756742994574\n","FOLD: 2, EPOCH: 16, train_loss: 0.01683767483679249\n","FOLD: 2, EPOCH: 16, valid_loss: 0.016814427696825826\n","FOLD: 2, EPOCH: 17, train_loss: 0.016690753283910453\n","FOLD: 2, EPOCH: 17, valid_loss: 0.01667740532909246\n","FOLD: 2, EPOCH: 18, train_loss: 0.01658100902568549\n","FOLD: 2, EPOCH: 18, valid_loss: 0.0165197323076427\n","FOLD: 2, EPOCH: 19, train_loss: 0.01620635109515313\n","FOLD: 2, EPOCH: 19, valid_loss: 0.016434509937158403\n","FOLD: 2, EPOCH: 20, train_loss: 0.015929489163681865\n","FOLD: 2, EPOCH: 20, valid_loss: 0.016345357768894994\n","FOLD: 2, EPOCH: 21, train_loss: 0.015680958277217168\n","FOLD: 2, EPOCH: 21, valid_loss: 0.01622444689821671\n","FOLD: 2, EPOCH: 22, train_loss: 0.015440345899311496\n","FOLD: 2, EPOCH: 22, valid_loss: 0.01615223806241856\n","FOLD: 2, EPOCH: 23, train_loss: 0.01532849800937316\n","FOLD: 2, EPOCH: 23, valid_loss: 0.01620482823208851\n","FOLD: 2, EPOCH: 24, train_loss: 0.015231536393163396\n","FOLD: 2, EPOCH: 24, valid_loss: 0.016129114391172632\n","FOLD: 3, EPOCH: 0, train_loss: 0.5472301742445458\n","FOLD: 3, EPOCH: 0, valid_loss: 0.03744609336204389\n","FOLD: 3, EPOCH: 1, train_loss: 0.024405537077280527\n","FOLD: 3, EPOCH: 1, valid_loss: 0.020595701575717506\n","FOLD: 3, EPOCH: 2, train_loss: 0.020157754592433134\n","FOLD: 3, EPOCH: 2, valid_loss: 0.01867813096546075\n","FOLD: 3, EPOCH: 3, train_loss: 0.019186301471884635\n","FOLD: 3, EPOCH: 3, valid_loss: 0.018016189994180903\n","FOLD: 3, EPOCH: 4, train_loss: 0.01836223297697656\n","FOLD: 3, EPOCH: 4, valid_loss: 0.017721066470531857\n","FOLD: 3, EPOCH: 5, train_loss: 0.017907853772425476\n","FOLD: 3, EPOCH: 5, valid_loss: 0.017349919002941427\n","FOLD: 3, EPOCH: 6, train_loss: 0.017713526037850362\n","FOLD: 3, EPOCH: 6, valid_loss: 0.01734676746213261\n","FOLD: 3, EPOCH: 7, train_loss: 0.01753384936327005\n","FOLD: 3, EPOCH: 7, valid_loss: 0.017323602456599474\n","FOLD: 3, EPOCH: 8, train_loss: 0.017515414298566824\n","FOLD: 3, EPOCH: 8, valid_loss: 0.0172001982710379\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[125], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(test), \u001b[38;5;28mlen\u001b[39m(target_cols)))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m SEED:\n\u001b[0;32m----> 9\u001b[0m     oof_, predictions_ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_k_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNFOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     oof \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m oof_ \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(SEED)\n\u001b[1;32m     11\u001b[0m     predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m predictions_ \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(SEED)\n","Cell \u001b[0;32mIn[123], line 6\u001b[0m, in \u001b[0;36mrun_k_fold\u001b[0;34m(NFOLDS, seed)\u001b[0m\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(test), \u001b[38;5;28mlen\u001b[39m(target_cols)))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NFOLDS):\n\u001b[0;32m----> 6\u001b[0m     oof_, pred_ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pred_ \u001b[38;5;241m/\u001b[39m NFOLDS\n\u001b[1;32m      9\u001b[0m     oof \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m oof_\n","Cell \u001b[0;32mIn[122], line 44\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(fold, seed)\u001b[0m\n\u001b[1;32m     40\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 44\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOLD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, EPOCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m     valid_loss, valid_preds \u001b[38;5;241m=\u001b[39m valid_fn(model, loss_fn, validloader, DEVICE)\n","Cell \u001b[0;32mIn[117], line 5\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, optimizer, scheduler, loss_fn, dataloader, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m final_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[116], line 11\u001b[0m, in \u001b[0;36mMoADataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     10\u001b[0m     dct \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m : torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat),\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m : torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[idx, :]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)            \n\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dct\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Averaging on multiple SEEDS\n","\n","SEED = [0, 1, 2, 3 ,4, 5]\n","oof = np.zeros((len(train), len(target_cols)))\n","predictions = np.zeros((len(test), len(target_cols)))\n","\n","for seed in SEED:\n","    \n","    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n","    oof += oof_ / len(SEED)\n","    predictions += predictions_ / len(SEED)\n","\n","train[target_cols] = oof\n","test[target_cols] = predictions\n"]},{"cell_type":"code","execution_count":64,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# test['atp-sensitive_potassium_channel_antagonist'] = 0.0\n","# test['erbb2_inhibitor'] = 0.0\n","\n","# train['atp-sensitive_potassium_channel_antagonist'] = 0.0\n","# train['erbb2_inhibitor'] = 0.0"]},{"cell_type":"code","execution_count":65,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>5-alpha_reductase_inhibitor</th>\n","      <th>11-beta-hsd1_inhibitor</th>\n","      <th>acat_inhibitor</th>\n","      <th>acetylcholine_receptor_agonist</th>\n","      <th>acetylcholine_receptor_antagonist</th>\n","      <th>acetylcholinesterase_inhibitor</th>\n","      <th>adenosine_receptor_agonist</th>\n","      <th>adenosine_receptor_antagonist</th>\n","      <th>adenylyl_cyclase_activator</th>\n","      <th>...</th>\n","      <th>tropomyosin_receptor_kinase_inhibitor</th>\n","      <th>trpv_agonist</th>\n","      <th>trpv_antagonist</th>\n","      <th>tubulin_inhibitor</th>\n","      <th>tyrosine_kinase_inhibitor</th>\n","      <th>ubiquitin_specific_protease_inhibitor</th>\n","      <th>vegfr_inhibitor</th>\n","      <th>vitamin_b</th>\n","      <th>vitamin_d_receptor_agonist</th>\n","      <th>wnt_inhibitor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>23809</th>\n","      <td>id_fffb1ceed</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23810</th>\n","      <td>id_fffb70c0c</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23811</th>\n","      <td>id_fffc1c3f4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23812</th>\n","      <td>id_fffcb9e7c</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23813</th>\n","      <td>id_ffffdd77b</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23814 rows × 207 columns</p>\n","</div>"],"text/plain":["             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor   \n","0      id_000644bb2                            0                       0  \\\n","1      id_000779bfc                            0                       0   \n","2      id_000a6266a                            0                       0   \n","3      id_0015fd391                            0                       0   \n","4      id_001626bd3                            0                       0   \n","...             ...                          ...                     ...   \n","23809  id_fffb1ceed                            0                       0   \n","23810  id_fffb70c0c                            0                       0   \n","23811  id_fffc1c3f4                            0                       0   \n","23812  id_fffcb9e7c                            0                       0   \n","23813  id_ffffdd77b                            0                       0   \n","\n","       acat_inhibitor  acetylcholine_receptor_agonist   \n","0                   0                               0  \\\n","1                   0                               0   \n","2                   0                               0   \n","3                   0                               0   \n","4                   0                               0   \n","...               ...                             ...   \n","23809               0                               0   \n","23810               0                               0   \n","23811               0                               0   \n","23812               0                               0   \n","23813               0                               0   \n","\n","       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor   \n","0                                      0                               0  \\\n","1                                      0                               0   \n","2                                      0                               0   \n","3                                      0                               0   \n","4                                      0                               0   \n","...                                  ...                             ...   \n","23809                                  0                               0   \n","23810                                  0                               0   \n","23811                                  0                               0   \n","23812                                  0                               0   \n","23813                                  0                               0   \n","\n","       adenosine_receptor_agonist  adenosine_receptor_antagonist   \n","0                               0                              0  \\\n","1                               0                              0   \n","2                               0                              0   \n","3                               0                              0   \n","4                               0                              0   \n","...                           ...                            ...   \n","23809                           0                              0   \n","23810                           0                              0   \n","23811                           0                              0   \n","23812                           0                              0   \n","23813                           0                              0   \n","\n","       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor   \n","0                               0  ...                                      0  \\\n","1                               0  ...                                      0   \n","2                               0  ...                                      0   \n","3                               0  ...                                      0   \n","4                               0  ...                                      0   \n","...                           ...  ...                                    ...   \n","23809                           0  ...                                      0   \n","23810                           0  ...                                      0   \n","23811                           0  ...                                      0   \n","23812                           0  ...                                      0   \n","23813                           0  ...                                      0   \n","\n","       trpv_agonist  trpv_antagonist  tubulin_inhibitor   \n","0                 0                0                  0  \\\n","1                 0                0                  0   \n","2                 0                0                  0   \n","3                 0                0                  0   \n","4                 0                0                  0   \n","...             ...              ...                ...   \n","23809             0                0                  0   \n","23810             0                0                  0   \n","23811             0                0                  0   \n","23812             0                0                  0   \n","23813             0                0                  0   \n","\n","       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor   \n","0                              0                                      0  \\\n","1                              0                                      0   \n","2                              0                                      0   \n","3                              0                                      0   \n","4                              0                                      0   \n","...                          ...                                    ...   \n","23809                          0                                      0   \n","23810                          0                                      0   \n","23811                          0                                      0   \n","23812                          0                                      0   \n","23813                          0                                      0   \n","\n","       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n","0                    0          0                           0              0  \n","1                    0          0                           0              0  \n","2                    0          0                           0              0  \n","3                    0          0                           0              0  \n","4                    0          0                           0              0  \n","...                ...        ...                         ...            ...  \n","23809                0          0                           0              0  \n","23810                0          0                           0              0  \n","23811                0          0                           0              0  \n","23812                0          0                           0              0  \n","23813                0          0                           0              0  \n","\n","[23814 rows x 207 columns]"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["train_targets_scored"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(target_cols)\n"]},{"cell_type":"code","execution_count":66,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CV log_loss:  0.014652433808298056\n"]}],"source":["valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n","\n","\n","y_true = train_targets_scored[target_cols].values\n","y_pred = valid_results[target_cols].values\n","\n","score = 0\n","for i in range(len(target_cols)):\n","    score_ = log_loss(y_true[:, i], y_pred[:, i])\n","    score += score_ / target.shape[1]\n","    \n","print(\"CV log_loss: \", score)"]},{"cell_type":"code","execution_count":67,"metadata":{"trusted":true},"outputs":[],"source":["sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n","sub.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n"]}],"source":["# import torch\n","# import torch.nn as nn\n","# import torch.onnx as onnx\n","\n","# # 定义模型\n","# class Model(nn.Module):\n","#     def __init__(self, num_features, num_targets, hidden_size):\n","#         super(Model, self).__init__()\n","#         self.batch_norm1 = nn.BatchNorm1d(num_features)\n","#         self.dropout1 = nn.Dropout(0.2)\n","#         self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n","\n","#         self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n","#         self.dropout2 = nn.Dropout(0.5)\n","#         self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n","\n","#         self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n","#         self.dropout3 = nn.Dropout(0.5)\n","#         self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n","\n","#     def forward(self, x):\n","#         x = self.batch_norm1(x)\n","#         x = self.dropout1(x)\n","#         x = torch.relu(self.dense1(x))\n","\n","#         x = self.batch_norm2(x)\n","#         x = self.dropout2(x)\n","#         x = torch.relu(self.dense2(x))\n","\n","#         x = self.batch_norm3(x)\n","#         x = self.dropout3(x)\n","#         x = self.dense3(x)\n","\n","#         return x\n","\n","# # 创建模型实例\n","# model = Model(num_features=num_features, num_targets=num_targets, hidden_size=hidden_size)\n","\n","# # 创建一个示例输入\n","# x = torch.randn(21948, num_features)\n","\n","# # 导出模型为ONNX格式\n","# torch.onnx.export(model,  # 导出的模型\n","#                   x,  # 输入数据\n","#                   \"model.onnx\",  # 导出的文件路径\n","#                   )  # 显示详细信息\n"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting onnx\n","  Downloading onnx-1.14.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.20.2 in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (4.23.0)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (4.5.0)\n","Requirement already satisfied: numpy in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (1.24.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.14.0\n"]}],"source":["!pip install onnx"]},{"cell_type":"markdown","metadata":{},"source":["## Things that can improve your CV even further:\n","1. Increasing SEEDS\n","2. Feature Selection over GENES/CELLS columns\n","3. Model Hyperparameter Tuning\n","4. Removing Skewness from GENES/CELLS columns [Comment below if it helps]\n","5. PCA........................................[Comment below if it helps]\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.16 ('ann')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"c5aa68934cf576379d06986a60942effae75d2e29c28cc454c328232c9ed20eb"}}},"nbformat":4,"nbformat_minor":4}
