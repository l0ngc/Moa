{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import copy\n","import seaborn as sns\n","\n","from sklearn import preprocessing\n","from sklearn.metrics import log_loss\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from model_cnn import *\n","from model_dnn import *\n","from model_lstm import *\n","import sys\n","sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n","# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# Read data\n","data_dir = '../data/'\n","train_features = pd.read_csv(data_dir + 'train_features.csv')\n","train_targets_scored = pd.read_csv(data_dir + 'train_targets_scored.csv')\n","train_targets_nonscored = pd.read_csv(data_dir + 'train_targets_nonscored.csv')\n","\n","test_features = pd.read_csv(data_dir + 'test_features.csv')\n","sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["# select Genes col and cells col\n","GENES = [col for col in train_features.columns if col.startswith('g-')]\n","CELLS = [col for col in train_features.columns if col.startswith('c-')]\n","target_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["# global seed for every envirment\n","global_random_seed = 42\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=global_random_seed)"]},{"cell_type":"markdown","metadata":{},"source":["# Remove outliers"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# # normalize data, drop outliers beyond 4 times standard\n","# train_ = train_features.copy()\n","# drop_set = set()\n","# for col in GENES:\n","    \n","#     mean = train_[col].mean()\n","#     std = train_[col].std()\n","\n","#     std_r = mean + 4*std\n","#     std_l = mean - 4*std\n","\n","#     drop_set = drop_set | set(train_[col][(train_[col]>std_r) | (train_[col]<std_l)].index.values)\n","\n","# train_features = train_features.drop(drop_set).reset_index(drop=True)\n","# train_targets_scored = train_targets_scored.drop(drop_set).reset_index(drop=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["# PCA features + Existing features"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["# Because there are lots of genes expression and cols, some of them are highly correlated\n","# which means we can cut off some unnecessary features to make data cleaner\n","# GENES\n","n_comp = 50\n","\n","data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n","data2 = (PCA(n_components=n_comp, random_state=global_random_seed).fit_transform(data[GENES]))\n","# split the pca processed file back to train and test\n","train2 = data2[:train_features.shape[0]]\n","test2 = data2[-test_features.shape[0]:]\n","\n","# then use the pca sampled data to generate a new dataframe\n","train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n","test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n","# concat the PCA processed df back to original one\n","# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n","train_features = pd.concat((train_features, train2), axis=1)\n","test_features = pd.concat((test_features, test2), axis=1)"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["#CELLS\n","n_comp = 15\n","\n","data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n","data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n","\n","train2 = data2[:train_features.shape[0]]\n","test2 = data2[-test_features.shape[0]:]\n","\n","train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n","test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n","\n","# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n","train_features = pd.concat((train_features, train2), axis=1)\n","test_features = pd.concat((test_features, test2), axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["# feature Selection using Variance Encoding"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>cp_type</th>\n","      <th>cp_time</th>\n","      <th>cp_dose</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>...</th>\n","      <th>917</th>\n","      <th>918</th>\n","      <th>919</th>\n","      <th>920</th>\n","      <th>921</th>\n","      <th>922</th>\n","      <th>923</th>\n","      <th>924</th>\n","      <th>925</th>\n","      <th>926</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>1.0620</td>\n","      <td>0.5577</td>\n","      <td>-0.2479</td>\n","      <td>-0.6208</td>\n","      <td>-0.1944</td>\n","      <td>-1.0120</td>\n","      <td>...</td>\n","      <td>-0.450285</td>\n","      <td>-0.176778</td>\n","      <td>-1.262943</td>\n","      <td>0.219107</td>\n","      <td>-0.890670</td>\n","      <td>0.393604</td>\n","      <td>-0.703376</td>\n","      <td>-0.615139</td>\n","      <td>0.174407</td>\n","      <td>0.082941</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.0743</td>\n","      <td>0.4087</td>\n","      <td>0.2991</td>\n","      <td>0.0604</td>\n","      <td>1.0190</td>\n","      <td>0.5207</td>\n","      <td>...</td>\n","      <td>0.063234</td>\n","      <td>0.658824</td>\n","      <td>0.429385</td>\n","      <td>-0.226422</td>\n","      <td>0.271831</td>\n","      <td>0.863835</td>\n","      <td>0.003597</td>\n","      <td>0.669397</td>\n","      <td>0.447651</td>\n","      <td>1.207365</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>0.6280</td>\n","      <td>0.5817</td>\n","      <td>1.5540</td>\n","      <td>-0.0764</td>\n","      <td>-0.0323</td>\n","      <td>1.2390</td>\n","      <td>...</td>\n","      <td>-0.115802</td>\n","      <td>0.726273</td>\n","      <td>-0.212644</td>\n","      <td>-0.902482</td>\n","      <td>-0.118799</td>\n","      <td>-0.336548</td>\n","      <td>0.015536</td>\n","      <td>0.572233</td>\n","      <td>-0.261651</td>\n","      <td>-0.638141</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.5138</td>\n","      <td>-0.2491</td>\n","      <td>-0.2656</td>\n","      <td>0.5288</td>\n","      <td>4.0620</td>\n","      <td>-0.8095</td>\n","      <td>...</td>\n","      <td>0.590366</td>\n","      <td>0.698760</td>\n","      <td>0.050321</td>\n","      <td>-0.793301</td>\n","      <td>0.295411</td>\n","      <td>0.147857</td>\n","      <td>0.056161</td>\n","      <td>0.689218</td>\n","      <td>-1.433683</td>\n","      <td>1.323147</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>-0.3254</td>\n","      <td>-0.4009</td>\n","      <td>0.9700</td>\n","      <td>0.6919</td>\n","      <td>1.4180</td>\n","      <td>-0.8244</td>\n","      <td>...</td>\n","      <td>-0.000223</td>\n","      <td>-0.287454</td>\n","      <td>-0.110246</td>\n","      <td>-0.105291</td>\n","      <td>-0.396913</td>\n","      <td>0.090983</td>\n","      <td>-0.211590</td>\n","      <td>0.350304</td>\n","      <td>-0.326626</td>\n","      <td>-0.344389</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>23809</th>\n","      <td>id_fffb1ceed</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>0.1394</td>\n","      <td>-0.0636</td>\n","      <td>-0.1112</td>\n","      <td>-0.5080</td>\n","      <td>-0.4713</td>\n","      <td>0.7201</td>\n","      <td>...</td>\n","      <td>-0.492270</td>\n","      <td>0.802396</td>\n","      <td>0.332499</td>\n","      <td>-0.204876</td>\n","      <td>0.238577</td>\n","      <td>-0.483204</td>\n","      <td>0.585078</td>\n","      <td>0.173586</td>\n","      <td>-0.611718</td>\n","      <td>1.607084</td>\n","    </tr>\n","    <tr>\n","      <th>23810</th>\n","      <td>id_fffb70c0c</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>-1.3260</td>\n","      <td>0.3478</td>\n","      <td>-0.3743</td>\n","      <td>0.9905</td>\n","      <td>-0.7178</td>\n","      <td>0.6621</td>\n","      <td>...</td>\n","      <td>-1.364079</td>\n","      <td>-0.375444</td>\n","      <td>-1.433534</td>\n","      <td>-0.858483</td>\n","      <td>1.072457</td>\n","      <td>0.101450</td>\n","      <td>0.435098</td>\n","      <td>-0.219500</td>\n","      <td>0.377156</td>\n","      <td>0.555680</td>\n","    </tr>\n","    <tr>\n","      <th>23811</th>\n","      <td>id_fffc1c3f4</td>\n","      <td>ctl_vehicle</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>0.3942</td>\n","      <td>0.3756</td>\n","      <td>0.3109</td>\n","      <td>-0.7389</td>\n","      <td>0.5505</td>\n","      <td>-0.0159</td>\n","      <td>...</td>\n","      <td>-0.511130</td>\n","      <td>-0.035609</td>\n","      <td>-0.310135</td>\n","      <td>-0.166686</td>\n","      <td>-0.458886</td>\n","      <td>-0.003948</td>\n","      <td>0.292592</td>\n","      <td>0.331622</td>\n","      <td>-0.006669</td>\n","      <td>0.081750</td>\n","    </tr>\n","    <tr>\n","      <th>23812</th>\n","      <td>id_fffcb9e7c</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>0.6660</td>\n","      <td>0.2324</td>\n","      <td>0.4392</td>\n","      <td>0.2044</td>\n","      <td>0.8531</td>\n","      <td>-0.0343</td>\n","      <td>...</td>\n","      <td>-1.129357</td>\n","      <td>0.020524</td>\n","      <td>-0.043233</td>\n","      <td>-0.440007</td>\n","      <td>0.302835</td>\n","      <td>0.776086</td>\n","      <td>-1.737516</td>\n","      <td>-0.531532</td>\n","      <td>-0.351892</td>\n","      <td>0.542268</td>\n","    </tr>\n","    <tr>\n","      <th>23813</th>\n","      <td>id_ffffdd77b</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>-0.8598</td>\n","      <td>1.0240</td>\n","      <td>-0.1361</td>\n","      <td>0.7952</td>\n","      <td>-0.3611</td>\n","      <td>-3.6750</td>\n","      <td>...</td>\n","      <td>3.549881</td>\n","      <td>0.367554</td>\n","      <td>1.124858</td>\n","      <td>2.358549</td>\n","      <td>4.598061</td>\n","      <td>0.405195</td>\n","      <td>0.448931</td>\n","      <td>3.509945</td>\n","      <td>1.710206</td>\n","      <td>-2.434251</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23814 rows × 931 columns</p>\n","</div>"],"text/plain":["             sig_id      cp_type cp_time cp_dose       0       1       2   \n","0      id_000644bb2       trt_cp      24      D1  1.0620  0.5577 -0.2479  \\\n","1      id_000779bfc       trt_cp      72      D1  0.0743  0.4087  0.2991   \n","2      id_000a6266a       trt_cp      48      D1  0.6280  0.5817  1.5540   \n","3      id_0015fd391       trt_cp      48      D1 -0.5138 -0.2491 -0.2656   \n","4      id_001626bd3       trt_cp      72      D2 -0.3254 -0.4009  0.9700   \n","...             ...          ...     ...     ...     ...     ...     ...   \n","23809  id_fffb1ceed       trt_cp      24      D2  0.1394 -0.0636 -0.1112   \n","23810  id_fffb70c0c       trt_cp      24      D2 -1.3260  0.3478 -0.3743   \n","23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.3942  0.3756  0.3109   \n","23812  id_fffcb9e7c       trt_cp      24      D1  0.6660  0.2324  0.4392   \n","23813  id_ffffdd77b       trt_cp      72      D1 -0.8598  1.0240 -0.1361   \n","\n","            3       4       5  ...       917       918       919       920   \n","0     -0.6208 -0.1944 -1.0120  ... -0.450285 -0.176778 -1.262943  0.219107  \\\n","1      0.0604  1.0190  0.5207  ...  0.063234  0.658824  0.429385 -0.226422   \n","2     -0.0764 -0.0323  1.2390  ... -0.115802  0.726273 -0.212644 -0.902482   \n","3      0.5288  4.0620 -0.8095  ...  0.590366  0.698760  0.050321 -0.793301   \n","4      0.6919  1.4180 -0.8244  ... -0.000223 -0.287454 -0.110246 -0.105291   \n","...       ...     ...     ...  ...       ...       ...       ...       ...   \n","23809 -0.5080 -0.4713  0.7201  ... -0.492270  0.802396  0.332499 -0.204876   \n","23810  0.9905 -0.7178  0.6621  ... -1.364079 -0.375444 -1.433534 -0.858483   \n","23811 -0.7389  0.5505 -0.0159  ... -0.511130 -0.035609 -0.310135 -0.166686   \n","23812  0.2044  0.8531 -0.0343  ... -1.129357  0.020524 -0.043233 -0.440007   \n","23813  0.7952 -0.3611 -3.6750  ...  3.549881  0.367554  1.124858  2.358549   \n","\n","            921       922       923       924       925       926  \n","0     -0.890670  0.393604 -0.703376 -0.615139  0.174407  0.082941  \n","1      0.271831  0.863835  0.003597  0.669397  0.447651  1.207365  \n","2     -0.118799 -0.336548  0.015536  0.572233 -0.261651 -0.638141  \n","3      0.295411  0.147857  0.056161  0.689218 -1.433683  1.323147  \n","4     -0.396913  0.090983 -0.211590  0.350304 -0.326626 -0.344389  \n","...         ...       ...       ...       ...       ...       ...  \n","23809  0.238577 -0.483204  0.585078  0.173586 -0.611718  1.607084  \n","23810  1.072457  0.101450  0.435098 -0.219500  0.377156  0.555680  \n","23811 -0.458886 -0.003948  0.292592  0.331622 -0.006669  0.081750  \n","23812  0.302835  0.776086 -1.737516 -0.531532 -0.351892  0.542268  \n","23813  4.598061  0.405195  0.448931  3.509945  1.710206 -2.434251  \n","\n","[23814 rows x 931 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_selection import VarianceThreshold\n","# use variance threshold to collect columns\n","# remove low variance columns and features\n","var_thresh = VarianceThreshold(threshold=0.5)\n","# data = train_features.append(test_features)\n","data = pd.concat([train_features, test_features], axis = 0)\n","data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n","\n","# \n","train_features_transformed = data_transformed[ : train_features.shape[0]]\n","test_features_transformed = data_transformed[-test_features.shape[0] : ]\n","\n","\n","train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n","                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n","\n","train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n","\n","\n","test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n","                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n","\n","test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n","\n","train_features"]},{"cell_type":"markdown","metadata":{},"source":["# Binning"]},{"cell_type":"code","execution_count":9,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# for col in GENES:\n","#     train.loc[:, f'{col}_bin'] = pd.cut(train[col], bins=3, labels=False)\n","#     test.loc[:, f'{col}_bin'] = pd.cut(test[col], bins=3, labels=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Distribution plots"]},{"cell_type":"code","execution_count":10,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# plt.figure(figsize=(16,16))\n","# sns.set_style(\"whitegrid\")\n","\n","# gene_choice = np.random.choice(len(GENES), 16)\n","# for i, col in enumerate(gene_choice):\n","#     plt.subplot(4, 4, i+1)\n","#     plt.hist(train_features.loc[:, GENES[col]],bins=100, color='orange')\n","#     plt.title(GENES[col])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["train = train_features.merge(train_targets_scored, on='sig_id')\n","train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n","test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n","\n","train.drop(columns=['cp_type'], axis = 1, inplace=True)\n","test.drop(columns=['cp_type'], axis = 1, inplace=True)\n","\n","target = train[train_targets_scored.columns]"]},{"cell_type":"markdown","metadata":{},"source":["# CV folds"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>cp_time</th>\n","      <th>cp_dose</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>...</th>\n","      <th>trpv_agonist</th>\n","      <th>trpv_antagonist</th>\n","      <th>tubulin_inhibitor</th>\n","      <th>tyrosine_kinase_inhibitor</th>\n","      <th>ubiquitin_specific_protease_inhibitor</th>\n","      <th>vegfr_inhibitor</th>\n","      <th>vitamin_b</th>\n","      <th>vitamin_d_receptor_agonist</th>\n","      <th>wnt_inhibitor</th>\n","      <th>kfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>1.0620</td>\n","      <td>0.5577</td>\n","      <td>-0.2479</td>\n","      <td>-0.6208</td>\n","      <td>-0.1944</td>\n","      <td>-1.0120</td>\n","      <td>-1.0220</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.0743</td>\n","      <td>0.4087</td>\n","      <td>0.2991</td>\n","      <td>0.0604</td>\n","      <td>1.0190</td>\n","      <td>0.5207</td>\n","      <td>0.2341</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>0.6280</td>\n","      <td>0.5817</td>\n","      <td>1.5540</td>\n","      <td>-0.0764</td>\n","      <td>-0.0323</td>\n","      <td>1.2390</td>\n","      <td>0.1715</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.5138</td>\n","      <td>-0.2491</td>\n","      <td>-0.2656</td>\n","      <td>0.5288</td>\n","      <td>4.0620</td>\n","      <td>-0.8095</td>\n","      <td>-1.9590</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>-0.3254</td>\n","      <td>-0.4009</td>\n","      <td>0.9700</td>\n","      <td>0.6919</td>\n","      <td>1.4180</td>\n","      <td>-0.8244</td>\n","      <td>-0.2800</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21943</th>\n","      <td>id_fff8c2444</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.1608</td>\n","      <td>-1.0500</td>\n","      <td>0.2551</td>\n","      <td>-0.2239</td>\n","      <td>-0.2431</td>\n","      <td>0.4256</td>\n","      <td>-0.1166</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21944</th>\n","      <td>id_fffb1ceed</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>0.1394</td>\n","      <td>-0.0636</td>\n","      <td>-0.1112</td>\n","      <td>-0.5080</td>\n","      <td>-0.4713</td>\n","      <td>0.7201</td>\n","      <td>0.5773</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>21945</th>\n","      <td>id_fffb70c0c</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>-1.3260</td>\n","      <td>0.3478</td>\n","      <td>-0.3743</td>\n","      <td>0.9905</td>\n","      <td>-0.7178</td>\n","      <td>0.6621</td>\n","      <td>-0.2252</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21946</th>\n","      <td>id_fffcb9e7c</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>0.6660</td>\n","      <td>0.2324</td>\n","      <td>0.4392</td>\n","      <td>0.2044</td>\n","      <td>0.8531</td>\n","      <td>-0.0343</td>\n","      <td>0.0323</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21947</th>\n","      <td>id_ffffdd77b</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>-0.8598</td>\n","      <td>1.0240</td>\n","      <td>-0.1361</td>\n","      <td>0.7952</td>\n","      <td>-0.3611</td>\n","      <td>-3.6750</td>\n","      <td>-1.2420</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21948 rows × 1137 columns</p>\n","</div>"],"text/plain":["             sig_id cp_time cp_dose       0       1       2       3       4   \n","0      id_000644bb2      24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944  \\\n","1      id_000779bfc      72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n","2      id_000a6266a      48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323   \n","3      id_0015fd391      48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620   \n","4      id_001626bd3      72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180   \n","...             ...     ...     ...     ...     ...     ...     ...     ...   \n","21943  id_fff8c2444      72      D1  0.1608 -1.0500  0.2551 -0.2239 -0.2431   \n","21944  id_fffb1ceed      24      D2  0.1394 -0.0636 -0.1112 -0.5080 -0.4713   \n","21945  id_fffb70c0c      24      D2 -1.3260  0.3478 -0.3743  0.9905 -0.7178   \n","21946  id_fffcb9e7c      24      D1  0.6660  0.2324  0.4392  0.2044  0.8531   \n","21947  id_ffffdd77b      72      D1 -0.8598  1.0240 -0.1361  0.7952 -0.3611   \n","\n","            5       6  ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor   \n","0     -1.0120 -1.0220  ...             0                0                  0  \\\n","1      0.5207  0.2341  ...             0                0                  0   \n","2      1.2390  0.1715  ...             0                0                  0   \n","3     -0.8095 -1.9590  ...             0                0                  0   \n","4     -0.8244 -0.2800  ...             0                0                  0   \n","...       ...     ...  ...           ...              ...                ...   \n","21943  0.4256 -0.1166  ...             0                0                  0   \n","21944  0.7201  0.5773  ...             0                0                  0   \n","21945  0.6621 -0.2252  ...             0                0                  0   \n","21946 -0.0343  0.0323  ...             0                0                  0   \n","21947 -3.6750 -1.2420  ...             0                0                  0   \n","\n","       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor   \n","0                              0                                      0  \\\n","1                              0                                      0   \n","2                              0                                      0   \n","3                              0                                      0   \n","4                              0                                      0   \n","...                          ...                                    ...   \n","21943                          0                                      0   \n","21944                          0                                      0   \n","21945                          0                                      0   \n","21946                          0                                      0   \n","21947                          0                                      0   \n","\n","       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor   \n","0                    0          0                           0              0  \\\n","1                    0          0                           0              0   \n","2                    0          0                           0              0   \n","3                    0          0                           0              0   \n","4                    0          0                           0              0   \n","...                ...        ...                         ...            ...   \n","21943                0          0                           0              0   \n","21944                0          0                           0              0   \n","21945                0          0                           0              0   \n","21946                0          0                           0              0   \n","21947                0          0                           0              0   \n","\n","       kfold  \n","0          0  \n","1          2  \n","2          1  \n","3          2  \n","4          2  \n","...      ...  \n","21943      0  \n","21944      4  \n","21945      0  \n","21946      1  \n","21947      2  \n","\n","[21948 rows x 1137 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["folds = train.copy()\n","\n","mskf = MultilabelStratifiedKFold(n_splits=5)\n","\n","for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n","    folds.loc[v_idx, 'kfold'] = int(f)\n","\n","folds['kfold'] = folds['kfold'].astype(int)\n","folds"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(21948, 1136)\n","(21948, 1137)\n","(3624, 930)\n","(21948, 207)\n","(3982, 207)\n"]}],"source":["print(train.shape)\n","print(folds.shape)\n","print(test.shape)\n","print(target.shape)\n","print(sample_submission.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Classes"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["class MoADataset:\n","    def __init__(self, features, targets):\n","        self.features = features\n","        self.targets = targets\n","        \n","    def __len__(self):\n","        return (self.features.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        dct = {\n","            'x' : torch.tensor(self.features[idx, :].astype(np.float32), dtype=torch.float),\n","            'y' : torch.tensor(self.targets[idx, :].astype(np.float32), dtype=torch.float)            \n","        }\n","        return dct\n","    \n","class TestDataset:\n","    def __init__(self, features):\n","        self.features = features\n","        \n","    def __len__(self):\n","        return (self.features.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        dct = {\n","            'x' : torch.tensor(self.features[idx, :].astype(np.float32), dtype=torch.float)\n","        }\n","        return dct\n","    "]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n","    model.train()\n","    final_loss = 0\n","    \n","    for data in dataloader:\n","        optimizer.zero_grad()\n","        inputs, targets = data['x'].to(device), data['y'].to(device)\n","#         print(inputs.shape)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        final_loss += loss.item()\n","        \n","    final_loss /= len(dataloader)\n","    \n","    return final_loss\n","\n","\n","def valid_fn(model, loss_fn, dataloader, device):\n","    model.eval()\n","    final_loss = 0\n","    valid_preds = []\n","    \n","    for data in dataloader:\n","        inputs, targets = data['x'].to(device), data['y'].to(device)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, targets)\n","        \n","        final_loss += loss.item()\n","        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n","        \n","    final_loss /= len(dataloader)\n","    valid_preds = np.concatenate(valid_preds)\n","    \n","    return final_loss, valid_preds\n","\n","def inference_fn(model, dataloader, device):\n","    model.eval()\n","    preds = []\n","    \n","    for data in dataloader:\n","        inputs = data['x'].to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(inputs)\n","        \n","        preds.append(outputs.sigmoid().detach().cpu().numpy())\n","        \n","    preds = np.concatenate(preds)\n","    \n","    return preds\n","   \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["# load model\n","model_dict = {\n","    'CNN':CNN,\n","    'DNN':DNN,\n","    # 'AdvDNN':AdvDNN,\n","    'CNNv2':CNNv2,\n","    'lstm':lstm\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing steps"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["def process_data(data):\n","    \n","    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n","#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n","#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n","\n","# --------------------- Normalize ---------------------\n","#     for col in GENES:\n","#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n","    \n","#     for col in CELLS:\n","#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n","    \n","#--------------------- Removing Skewness ---------------------\n","#     for col in GENES + CELLS:\n","#         if(abs(data[col].skew()) > 0.75):\n","            \n","#             if(data[col].skew() < 0): # neg-skewness\n","#                 data[col] = data[col].max() - data[col] + 1\n","#                 data[col] = np.sqrt(data[col])\n","            \n","#             else:\n","#                 data[col] = np.sqrt(data[col])\n","    \n","    return data"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["932"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n","feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n","len(feature_cols)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["# HyperParameters\n","\n","DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n","EPOCHS = 25\n","BATCH_SIZE = 128\n","LEARNING_RATE = 1e-3\n","WEIGHT_DECAY = 1e-5\n","NFOLDS = 5\n","EARLY_STOPPING_STEPS = 10\n","EARLY_STOP = False\n","\n","num_features=len(feature_cols)\n","num_targets=len(target_cols)\n","hidden_size=1024\n","\n","target_model = 'lstm'\n"]},{"cell_type":"markdown","metadata":{},"source":["# Single fold training"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["def run_training(fold, seed, model_name):\n","    \n","    seed_everything(seed)\n","    \n","    train = process_data(folds)\n","    test_ = process_data(test)\n","    \n","    trn_idx = train[train['kfold'] != fold].index\n","    val_idx = train[train['kfold'] == fold].index\n","    \n","    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n","    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n","    \n","    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n","    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n","    \n","    train_dataset = MoADataset(x_train, y_train)\n","    valid_dataset = MoADataset(x_valid, y_valid)\n","    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","\n","    model = model_dict[model_name](\n","        num_features=num_features,\n","        num_targets=num_targets,\n","        hidden_size=hidden_size,\n","    )\n","    \n","    model.to(DEVICE)\n","    \n","    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n","                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n","    \n","    loss_fn = nn.BCEWithLogitsLoss()\n","    \n","    early_stopping_steps = EARLY_STOPPING_STEPS\n","    early_step = 0\n","    \n","    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n","    best_loss = np.inf\n","    \n","    for epoch in range(EPOCHS):\n","        \n","        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n","        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n","        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n","        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n","        \n","        if valid_loss < best_loss:\n","            \n","            best_loss = valid_loss\n","            oof[val_idx] = valid_preds\n","            torch.save(model.state_dict(), f\"{model_name}_FOLD{fold}_.pth\")\n","        \n","        elif(EARLY_STOP == True):\n","            \n","            early_step += 1\n","            if (early_step >= early_stopping_steps):\n","                break\n","            \n","    \n","    #--------------------- PREDICTION---------------------\n","    x_test = test_[feature_cols].values\n","    testdataset = TestDataset(x_test)\n","    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","\n","    model = model_dict[model_name](\n","        num_features=num_features,\n","        num_targets=num_targets,\n","        hidden_size=hidden_size,\n","    )\n","    \n","    model.load_state_dict(torch.load(f\"{model_name}_FOLD{fold}_.pth\"))\n","\n","    model.to(DEVICE)\n","    \n","    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n","    predictions = inference_fn(model, testloader, DEVICE)\n","    \n","    return oof, predictions\n"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["def run_k_fold(NFOLDS, seed):\n","    oof = np.zeros((len(train), len(target_cols)))\n","    predictions = np.zeros((len(test), len(target_cols)))\n","    \n","    for fold in range(NFOLDS):\n","        oof_, pred_ = run_training(fold, seed, target_model)\n","        \n","        predictions += pred_ / NFOLDS\n","        oof += oof_\n","        \n","    return oof, predictions"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["FOLD: 0, EPOCH: 0, train_loss: 0.6445290989417961\n","FOLD: 0, EPOCH: 0, valid_loss: 0.10863530146224158\n","FOLD: 0, EPOCH: 1, train_loss: 0.03206902998837008\n","FOLD: 0, EPOCH: 1, valid_loss: 0.02024705127945968\n","FOLD: 0, EPOCH: 2, train_loss: 0.021282336134733498\n","FOLD: 0, EPOCH: 2, valid_loss: 0.019172219399894986\n","FOLD: 0, EPOCH: 3, train_loss: 0.02014700112108519\n","FOLD: 0, EPOCH: 3, valid_loss: 0.01858037087534155\n","FOLD: 0, EPOCH: 4, train_loss: 0.019325564986607736\n","FOLD: 0, EPOCH: 4, valid_loss: 0.01809099561401776\n","FOLD: 0, EPOCH: 5, train_loss: 0.01882065042340453\n","FOLD: 0, EPOCH: 5, valid_loss: 0.017828410943703993\n","FOLD: 0, EPOCH: 6, train_loss: 0.01856545591052028\n","FOLD: 0, EPOCH: 6, valid_loss: 0.017551756011588232\n","FOLD: 0, EPOCH: 7, train_loss: 0.018431825259619432\n","FOLD: 0, EPOCH: 7, valid_loss: 0.017576747573912144\n","FOLD: 0, EPOCH: 8, train_loss: 0.018230096119847418\n","FOLD: 0, EPOCH: 8, valid_loss: 0.017300537042319774\n","FOLD: 0, EPOCH: 9, train_loss: 0.018021270706979692\n","FOLD: 0, EPOCH: 9, valid_loss: 0.017165633769971985\n","FOLD: 0, EPOCH: 10, train_loss: 0.017781198382431616\n","FOLD: 0, EPOCH: 10, valid_loss: 0.017077034126435006\n","FOLD: 0, EPOCH: 11, train_loss: 0.017717067550435877\n","FOLD: 0, EPOCH: 11, valid_loss: 0.016995120527488843\n","FOLD: 0, EPOCH: 12, train_loss: 0.01758283101346182\n","FOLD: 0, EPOCH: 12, valid_loss: 0.01694083149944033\n","FOLD: 0, EPOCH: 13, train_loss: 0.01751363611496661\n","FOLD: 0, EPOCH: 13, valid_loss: 0.016858674745474544\n","FOLD: 0, EPOCH: 14, train_loss: 0.017274742021454847\n","FOLD: 0, EPOCH: 14, valid_loss: 0.016769712125616416\n","FOLD: 0, EPOCH: 15, train_loss: 0.0171999400144146\n","FOLD: 0, EPOCH: 15, valid_loss: 0.01668166499584913\n","FOLD: 0, EPOCH: 16, train_loss: 0.01700235555704305\n","FOLD: 0, EPOCH: 16, valid_loss: 0.016641637177339623\n","FOLD: 0, EPOCH: 17, train_loss: 0.016822342868840347\n","FOLD: 0, EPOCH: 17, valid_loss: 0.016655136751277107\n","FOLD: 0, EPOCH: 18, train_loss: 0.016634062411722498\n","FOLD: 0, EPOCH: 18, valid_loss: 0.016562961733766965\n","FOLD: 0, EPOCH: 19, train_loss: 0.016450131703438103\n","FOLD: 0, EPOCH: 19, valid_loss: 0.016533356426017626\n","FOLD: 0, EPOCH: 20, train_loss: 0.016325067458809284\n","FOLD: 0, EPOCH: 20, valid_loss: 0.016441048974437374\n","FOLD: 0, EPOCH: 21, train_loss: 0.016078672412297\n","FOLD: 0, EPOCH: 21, valid_loss: 0.016421709608818804\n","FOLD: 0, EPOCH: 22, train_loss: 0.0159694018125858\n","FOLD: 0, EPOCH: 22, valid_loss: 0.016396626457571985\n","FOLD: 0, EPOCH: 23, train_loss: 0.015879107477224392\n","FOLD: 0, EPOCH: 23, valid_loss: 0.016393505595624448\n","FOLD: 0, EPOCH: 24, train_loss: 0.015880751288563446\n","FOLD: 0, EPOCH: 24, valid_loss: 0.01637933339391436\n","FOLD: 1, EPOCH: 0, train_loss: 0.6424303002979445\n","FOLD: 1, EPOCH: 0, valid_loss: 0.11462843311684472\n","FOLD: 1, EPOCH: 1, train_loss: 0.03175989669356225\n","FOLD: 1, EPOCH: 1, valid_loss: 0.020234752552849906\n","FOLD: 1, EPOCH: 2, train_loss: 0.021425710343148396\n","FOLD: 1, EPOCH: 2, valid_loss: 0.019200295848505838\n","FOLD: 1, EPOCH: 3, train_loss: 0.020163941548030445\n","FOLD: 1, EPOCH: 3, valid_loss: 0.018614843966705458\n","FOLD: 1, EPOCH: 4, train_loss: 0.01938421188759199\n","FOLD: 1, EPOCH: 4, valid_loss: 0.018125338133956705\n","FOLD: 1, EPOCH: 5, train_loss: 0.01890672376865278\n","FOLD: 1, EPOCH: 5, valid_loss: 0.017750882383968148\n","FOLD: 1, EPOCH: 6, train_loss: 0.018537870068373024\n","FOLD: 1, EPOCH: 6, valid_loss: 0.017518003737287863\n","FOLD: 1, EPOCH: 7, train_loss: 0.018399258839317423\n","FOLD: 1, EPOCH: 7, valid_loss: 0.0174756704430495\n","FOLD: 1, EPOCH: 8, train_loss: 0.01814428463821178\n","FOLD: 1, EPOCH: 8, valid_loss: 0.017356456789587225\n","FOLD: 1, EPOCH: 9, train_loss: 0.017951907704759767\n","FOLD: 1, EPOCH: 9, valid_loss: 0.0172635482358081\n","FOLD: 1, EPOCH: 10, train_loss: 0.01783130315226921\n","FOLD: 1, EPOCH: 10, valid_loss: 0.017156834501240933\n","FOLD: 1, EPOCH: 11, train_loss: 0.01769076941696846\n","FOLD: 1, EPOCH: 11, valid_loss: 0.017049151100218297\n","FOLD: 1, EPOCH: 12, train_loss: 0.017589714506344088\n","FOLD: 1, EPOCH: 12, valid_loss: 0.017025685576455934\n","FOLD: 1, EPOCH: 13, train_loss: 0.017439296529830797\n","FOLD: 1, EPOCH: 13, valid_loss: 0.01695475405348199\n","FOLD: 1, EPOCH: 14, train_loss: 0.017239819206567347\n","FOLD: 1, EPOCH: 14, valid_loss: 0.016878437623381613\n","FOLD: 1, EPOCH: 15, train_loss: 0.01711842975160782\n","FOLD: 1, EPOCH: 15, valid_loss: 0.01670533251017332\n","FOLD: 1, EPOCH: 16, train_loss: 0.016970767740808104\n","FOLD: 1, EPOCH: 16, valid_loss: 0.0166920414726649\n","FOLD: 1, EPOCH: 17, train_loss: 0.0167684115037538\n","FOLD: 1, EPOCH: 17, valid_loss: 0.016586261162800448\n","FOLD: 1, EPOCH: 18, train_loss: 0.016647531745442444\n","FOLD: 1, EPOCH: 18, valid_loss: 0.016537948484931675\n","FOLD: 1, EPOCH: 19, train_loss: 0.016451768381386133\n","FOLD: 1, EPOCH: 19, valid_loss: 0.01649545393884182\n","FOLD: 1, EPOCH: 20, train_loss: 0.016263173413935347\n","FOLD: 1, EPOCH: 20, valid_loss: 0.016481634389076915\n","FOLD: 1, EPOCH: 21, train_loss: 0.016071227372394525\n","FOLD: 1, EPOCH: 21, valid_loss: 0.016421769532774175\n","FOLD: 1, EPOCH: 22, train_loss: 0.01595135494067833\n","FOLD: 1, EPOCH: 22, valid_loss: 0.016388453197266374\n","FOLD: 1, EPOCH: 23, train_loss: 0.015871875028571358\n","FOLD: 1, EPOCH: 23, valid_loss: 0.01637568167809929\n","FOLD: 1, EPOCH: 24, train_loss: 0.015846486135885334\n","FOLD: 1, EPOCH: 24, valid_loss: 0.016370671242475508\n","FOLD: 2, EPOCH: 0, train_loss: 0.6422277190115141\n","FOLD: 2, EPOCH: 0, valid_loss: 0.11795590903077807\n","FOLD: 2, EPOCH: 1, train_loss: 0.03178140322637299\n","FOLD: 2, EPOCH: 1, valid_loss: 0.020075058937072753\n","FOLD: 2, EPOCH: 2, train_loss: 0.021182076195659844\n","FOLD: 2, EPOCH: 2, valid_loss: 0.01910673353288855\n","FOLD: 2, EPOCH: 3, train_loss: 0.01997379812857379\n","FOLD: 2, EPOCH: 3, valid_loss: 0.018428419716656208\n","FOLD: 2, EPOCH: 4, train_loss: 0.019273513739091763\n","FOLD: 2, EPOCH: 4, valid_loss: 0.01798017408166613\n","FOLD: 2, EPOCH: 5, train_loss: 0.01881344681200774\n","FOLD: 2, EPOCH: 5, valid_loss: 0.017859393837196487\n","FOLD: 2, EPOCH: 6, train_loss: 0.018591490176006937\n","FOLD: 2, EPOCH: 6, valid_loss: 0.01767281073012522\n","FOLD: 2, EPOCH: 7, train_loss: 0.01833059847948776\n","FOLD: 2, EPOCH: 7, valid_loss: 0.017433906719088555\n","FOLD: 2, EPOCH: 8, train_loss: 0.018128684370953968\n","FOLD: 2, EPOCH: 8, valid_loss: 0.017311552965215273\n","FOLD: 2, EPOCH: 9, train_loss: 0.01797548858313889\n","FOLD: 2, EPOCH: 9, valid_loss: 0.017247893528214524\n","FOLD: 2, EPOCH: 10, train_loss: 0.0178466296174388\n","FOLD: 2, EPOCH: 10, valid_loss: 0.01712163125297853\n","FOLD: 2, EPOCH: 11, train_loss: 0.01768641379000484\n","FOLD: 2, EPOCH: 11, valid_loss: 0.016980545009885516\n","FOLD: 2, EPOCH: 12, train_loss: 0.017580686501510765\n","FOLD: 2, EPOCH: 12, valid_loss: 0.016922406346670218\n","FOLD: 2, EPOCH: 13, train_loss: 0.01741126737813803\n","FOLD: 2, EPOCH: 13, valid_loss: 0.016849604515092712\n","FOLD: 2, EPOCH: 14, train_loss: 0.01725217551532863\n","FOLD: 2, EPOCH: 14, valid_loss: 0.01679179897265775\n","FOLD: 2, EPOCH: 15, train_loss: 0.017124510302707768\n","FOLD: 2, EPOCH: 15, valid_loss: 0.016665531827935152\n","FOLD: 2, EPOCH: 16, train_loss: 0.016998903576176668\n","FOLD: 2, EPOCH: 16, valid_loss: 0.016625435064945904\n","FOLD: 2, EPOCH: 17, train_loss: 0.016806839175684297\n","FOLD: 2, EPOCH: 17, valid_loss: 0.016577814173485552\n","FOLD: 2, EPOCH: 18, train_loss: 0.016666544101916363\n","FOLD: 2, EPOCH: 18, valid_loss: 0.016505855375102588\n","FOLD: 2, EPOCH: 19, train_loss: 0.016475601938377687\n","FOLD: 2, EPOCH: 19, valid_loss: 0.016455783056361334\n","FOLD: 2, EPOCH: 20, train_loss: 0.016288206656126007\n","FOLD: 2, EPOCH: 20, valid_loss: 0.016420867799648218\n","FOLD: 2, EPOCH: 21, train_loss: 0.016097515295057194\n","FOLD: 2, EPOCH: 21, valid_loss: 0.016372132966560978\n","FOLD: 2, EPOCH: 22, train_loss: 0.01591366291909978\n","FOLD: 2, EPOCH: 22, valid_loss: 0.0163533427087324\n","FOLD: 2, EPOCH: 23, train_loss: 0.015890101078843723\n","FOLD: 2, EPOCH: 23, valid_loss: 0.016281588508614473\n","FOLD: 2, EPOCH: 24, train_loss: 0.015812848816099373\n","FOLD: 2, EPOCH: 24, valid_loss: 0.016299162272896087\n","FOLD: 3, EPOCH: 0, train_loss: 0.645055082505164\n","FOLD: 3, EPOCH: 0, valid_loss: 0.12670746807541167\n","FOLD: 3, EPOCH: 1, train_loss: 0.03253106701363256\n","FOLD: 3, EPOCH: 1, valid_loss: 0.020332971374903405\n","FOLD: 3, EPOCH: 2, train_loss: 0.021282137182635674\n","FOLD: 3, EPOCH: 2, valid_loss: 0.019329702694501197\n","FOLD: 3, EPOCH: 3, train_loss: 0.0202837021805454\n","FOLD: 3, EPOCH: 3, valid_loss: 0.01881964776132788\n","FOLD: 3, EPOCH: 4, train_loss: 0.019553312532387783\n","FOLD: 3, EPOCH: 4, valid_loss: 0.01845297621829169\n","FOLD: 3, EPOCH: 5, train_loss: 0.01904330637467944\n","FOLD: 3, EPOCH: 5, valid_loss: 0.018093943649104664\n","FOLD: 3, EPOCH: 6, train_loss: 0.018758200473435547\n","FOLD: 3, EPOCH: 6, valid_loss: 0.017831874931497235\n","FOLD: 3, EPOCH: 7, train_loss: 0.01847545749278388\n","FOLD: 3, EPOCH: 7, valid_loss: 0.017707216367125512\n","FOLD: 3, EPOCH: 8, train_loss: 0.018309788548967976\n","FOLD: 3, EPOCH: 8, valid_loss: 0.017653927180383888\n","FOLD: 3, EPOCH: 9, train_loss: 0.01813048218795355\n","FOLD: 3, EPOCH: 9, valid_loss: 0.017487845889159612\n","FOLD: 3, EPOCH: 10, train_loss: 0.017880770013384197\n","FOLD: 3, EPOCH: 10, valid_loss: 0.017426837714655058\n","FOLD: 3, EPOCH: 11, train_loss: 0.01780454039681649\n","FOLD: 3, EPOCH: 11, valid_loss: 0.01728712341615132\n","FOLD: 3, EPOCH: 12, train_loss: 0.017648871927319662\n","FOLD: 3, EPOCH: 12, valid_loss: 0.017219337395259313\n","FOLD: 3, EPOCH: 13, train_loss: 0.017466504727422758\n","FOLD: 3, EPOCH: 13, valid_loss: 0.01706639312739883\n","FOLD: 3, EPOCH: 14, train_loss: 0.0173497861723645\n","FOLD: 3, EPOCH: 14, valid_loss: 0.01710095139486449\n","FOLD: 3, EPOCH: 15, train_loss: 0.01714164108388882\n","FOLD: 3, EPOCH: 15, valid_loss: 0.01696242493178163\n","FOLD: 3, EPOCH: 16, train_loss: 0.01695996082212398\n","FOLD: 3, EPOCH: 16, valid_loss: 0.016835057203258785\n","FOLD: 3, EPOCH: 17, train_loss: 0.016812016411374014\n","FOLD: 3, EPOCH: 17, valid_loss: 0.01679470714713846\n","FOLD: 3, EPOCH: 18, train_loss: 0.01660459239602737\n","FOLD: 3, EPOCH: 18, valid_loss: 0.016715421501014915\n","FOLD: 3, EPOCH: 19, train_loss: 0.016431911416567753\n","FOLD: 3, EPOCH: 19, valid_loss: 0.016623786597379616\n","FOLD: 3, EPOCH: 20, train_loss: 0.016264170489233475\n","FOLD: 3, EPOCH: 20, valid_loss: 0.016630881678845202\n","FOLD: 3, EPOCH: 21, train_loss: 0.016059744428249374\n","FOLD: 3, EPOCH: 21, valid_loss: 0.016524675195770604\n","FOLD: 3, EPOCH: 22, train_loss: 0.01591574767118563\n","FOLD: 3, EPOCH: 22, valid_loss: 0.016534116278801646\n","FOLD: 3, EPOCH: 23, train_loss: 0.015777714078085148\n","FOLD: 3, EPOCH: 23, valid_loss: 0.016540946305862496\n","FOLD: 3, EPOCH: 24, train_loss: 0.01576570561155677\n","FOLD: 3, EPOCH: 24, valid_loss: 0.016532351981316293\n","FOLD: 4, EPOCH: 0, train_loss: 0.641125282353681\n","FOLD: 4, EPOCH: 0, valid_loss: 0.11296734575714384\n","FOLD: 4, EPOCH: 1, train_loss: 0.03189370432949584\n","FOLD: 4, EPOCH: 1, valid_loss: 0.02031933255493641\n","FOLD: 4, EPOCH: 2, train_loss: 0.021432048884098946\n","FOLD: 4, EPOCH: 2, valid_loss: 0.0193451712174075\n","FOLD: 4, EPOCH: 3, train_loss: 0.020310762014401997\n","FOLD: 4, EPOCH: 3, valid_loss: 0.01864805759063789\n","FOLD: 4, EPOCH: 4, train_loss: 0.01945749207980175\n","FOLD: 4, EPOCH: 4, valid_loss: 0.018257600468184268\n","FOLD: 4, EPOCH: 5, train_loss: 0.018944297296305496\n","FOLD: 4, EPOCH: 5, valid_loss: 0.01786132755556277\n","FOLD: 4, EPOCH: 6, train_loss: 0.01855883895136092\n","FOLD: 4, EPOCH: 6, valid_loss: 0.01765368634036609\n","FOLD: 4, EPOCH: 7, train_loss: 0.01832083060635605\n","FOLD: 4, EPOCH: 7, valid_loss: 0.017489324856017317\n","FOLD: 4, EPOCH: 8, train_loss: 0.018116952230532963\n","FOLD: 4, EPOCH: 8, valid_loss: 0.017409776683364596\n","FOLD: 4, EPOCH: 9, train_loss: 0.018013547417586265\n","FOLD: 4, EPOCH: 9, valid_loss: 0.017218852628554618\n","FOLD: 4, EPOCH: 10, train_loss: 0.01789640123699454\n","FOLD: 4, EPOCH: 10, valid_loss: 0.017213377596012183\n","FOLD: 4, EPOCH: 11, train_loss: 0.01768985229368875\n","FOLD: 4, EPOCH: 11, valid_loss: 0.017170729940491063\n","FOLD: 4, EPOCH: 12, train_loss: 0.01760544851962207\n","FOLD: 4, EPOCH: 12, valid_loss: 0.016957306569176062\n","FOLD: 4, EPOCH: 13, train_loss: 0.017353465045005945\n","FOLD: 4, EPOCH: 13, valid_loss: 0.016927295391048702\n","FOLD: 4, EPOCH: 14, train_loss: 0.01728208415021283\n","FOLD: 4, EPOCH: 14, valid_loss: 0.016800278371998243\n","FOLD: 4, EPOCH: 15, train_loss: 0.01712366696987031\n","FOLD: 4, EPOCH: 15, valid_loss: 0.016683615877160003\n","FOLD: 4, EPOCH: 16, train_loss: 0.01690125521407395\n","FOLD: 4, EPOCH: 16, valid_loss: 0.016631455932344708\n","FOLD: 4, EPOCH: 17, train_loss: 0.016752640008116545\n","FOLD: 4, EPOCH: 17, valid_loss: 0.01657323789383684\n","FOLD: 4, EPOCH: 18, train_loss: 0.016608675651630198\n","FOLD: 4, EPOCH: 18, valid_loss: 0.016502050842557636\n","FOLD: 4, EPOCH: 19, train_loss: 0.016453822345837303\n","FOLD: 4, EPOCH: 19, valid_loss: 0.01643313392996788\n","FOLD: 4, EPOCH: 20, train_loss: 0.016302825869533463\n","FOLD: 4, EPOCH: 20, valid_loss: 0.016378204098769597\n","FOLD: 4, EPOCH: 21, train_loss: 0.016091827627109444\n","FOLD: 4, EPOCH: 21, valid_loss: 0.016295890536691462\n","FOLD: 4, EPOCH: 22, train_loss: 0.015974368900060654\n","FOLD: 4, EPOCH: 22, valid_loss: 0.016312940418720244\n","FOLD: 4, EPOCH: 23, train_loss: 0.015865367169127516\n","FOLD: 4, EPOCH: 23, valid_loss: 0.01625677001263414\n","FOLD: 4, EPOCH: 24, train_loss: 0.01580194165201291\n","FOLD: 4, EPOCH: 24, valid_loss: 0.016254359377282007\n"]}],"source":["# Averaging on multiple SEEDS\n","\n","# SEED = [0, 1, 2, 3 ,4, 5]\n","SEED = [0]\n","oof = np.zeros((len(train), len(target_cols)))\n","predictions = np.zeros((len(test), len(target_cols)))\n","\n","for seed in SEED:\n","    \n","    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n","    oof += oof_ / len(SEED)\n","    predictions += predictions_ / len(SEED)\n","\n","train[target_cols] = oof\n","test[target_cols] = predictions\n"]},{"cell_type":"code","execution_count":23,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# test['atp-sensitive_potassium_channel_antagonist'] = 0.0\n","# test['erbb2_inhibitor'] = 0.0\n","\n","# train['atp-sensitive_potassium_channel_antagonist'] = 0.0\n","# train['erbb2_inhibitor'] = 0.0"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CV log_loss:  0.015048785035915769\n"]}],"source":["valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n","\n","y_true = train_targets_scored[target_cols].values\n","y_pred = valid_results[target_cols].values\n","\n","score = 0\n","for i in range(len(target_cols)):\n","    score_ = log_loss(y_true[:, i], y_pred[:, i])\n","    score += score_ / target.shape[1]\n","    \n","print(\"CV log_loss: \", score)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# test_ = process_data(test)\n","# x_test = test_[feature_cols].values\n","# testdataset = TestDataset(x_test)\n","# testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# model = model_dict[target_model](\n","#     num_features=num_features,\n","#     num_targets=num_targets,\n","#     hidden_size=hidden_size,\n","# )\n","\n","# model.load_state_dict(torch.load(f\"{target_model}_FOLD{4}_.pth\"))\n","\n","# model.to(DEVICE)\n","\n","# predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n","# predictions = inference_fn(model, testloader, DEVICE)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["res_dir = './results/'\n","valid_results.to_csv(f'{res_dir}{target_model}_result.csv', index = False)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Precision: 0.9917\n","Recall: 0.5966\n","F1 score: 0.7450\n","Accuracy score: 0.9592\n"]}],"source":["y_true = train_targets_scored[['nfkb_inhibitor','dopamine_receptor_antagonist','proteasome_inhibitor','cyclooxygenase_inhibitor']].values\n","y_pred = valid_results[['nfkb_inhibitor','dopamine_receptor_antagonist','proteasome_inhibitor','cyclooxygenase_inhibitor']].values\n","\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","# Assuming you have your predicted labels stored in 'y_pred' and true labels in 'y_true'\n","\n","# Calculate precision\n","precision = precision_score(y_true, (y_pred).round(), average='micro')\n","\n","# Calculate recall\n","recall = recall_score(y_true, (y_pred).round(), average='micro')\n","\n","# Calculate F1 score\n","f1 = f1_score(y_true, (y_pred).round(), average='micro')\n","\n","accuracy = accuracy_score(y_true, (y_pred).round())\n","# Print the results\n","print(\"Precision: {:.4f}\".format(precision))\n","print(\"Recall: {:.4f}\".format(recall))\n","print(\"F1 score: {:.4f}\".format(f1))\n","print(\"Accuracy score: {:.4f}\".format(accuracy))"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n","sub.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","# import torch.onnx as onnx\n","\n","# # 定义模型\n","# class Model(nn.Module):\n","#     def __init__(self, num_features, num_targets, hidden_size):\n","#         super(Model, self).__init__()\n","#         self.batch_norm1 = nn.BatchNorm1d(num_features)\n","#         self.dropout1 = nn.Dropout(0.2)\n","#         self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n","\n","#         self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n","#         self.dropout2 = nn.Dropout(0.5)\n","#         self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n","\n","#         self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n","#         self.dropout3 = nn.Dropout(0.5)\n","#         self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n","\n","#     def forward(self, x):\n","#         x = self.batch_norm1(x)\n","#         x = self.dropout1(x)\n","#         x = torch.relu(self.dense1(x))\n","\n","#         x = self.batch_norm2(x)\n","#         x = self.dropout2(x)\n","#         x = torch.relu(self.dense2(x))\n","\n","#         x = self.batch_norm3(x)\n","#         x = self.dropout3(x)\n","#         x = self.dense3(x)\n","\n","#         return x\n","\n","# # 创建模型实例\n","# model = Model(num_features=num_features, num_targets=num_targets, hidden_size=hidden_size)\n","\n","# # 创建一个示例输入\n","# x = torch.randn(21948, num_features)\n","\n","# # 导出模型为ONNX格式\n","# torch.onnx.export(model,  # 导出的模型\n","#                   x,  # 输入数据\n","#                   \"model.onnx\",  # 导出的文件路径\n","#                   )  # 显示详细信息\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: onnx in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (1.14.0)\n","Requirement already satisfied: protobuf>=3.20.2 in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (4.23.0)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (4.5.0)\n","Requirement already satisfied: numpy in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (1.24.3)\n"]}],"source":["!pip install onnx"]},{"cell_type":"markdown","metadata":{},"source":["## Things that can improve your CV even further:\n","1. Increasing SEEDS\n","2. Feature Selection over GENES/CELLS columns\n","3. Model Hyperparameter Tuning\n","4. Removing Skewness from GENES/CELLS columns [Comment below if it helps]\n","5. PCA........................................[Comment below if it helps]\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.16 ('ann')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"c5aa68934cf576379d06986a60942effae75d2e29c28cc454c328232c9ed20eb"}}},"nbformat":4,"nbformat_minor":4}
