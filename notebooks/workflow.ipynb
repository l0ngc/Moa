{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import copy\n","import seaborn as sns\n","\n","from sklearn import preprocessing\n","from sklearn.metrics import log_loss\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from model_cnn import *\n","from model_dnn import *\n","import sys\n","sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n","# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# Read data\n","data_dir = '../data/'\n","train_features = pd.read_csv(data_dir + 'train_features.csv')\n","train_targets_scored = pd.read_csv(data_dir + 'train_targets_scored.csv')\n","train_targets_nonscored = pd.read_csv(data_dir + 'train_targets_nonscored.csv')\n","\n","test_features = pd.read_csv(data_dir + 'test_features.csv')\n","sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["# select Genes col and cells col\n","GENES = [col for col in train_features.columns if col.startswith('g-')]\n","CELLS = [col for col in train_features.columns if col.startswith('c-')]\n","target_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["# global seed for every envirment\n","global_random_seed = 42\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=global_random_seed)"]},{"cell_type":"markdown","metadata":{},"source":["# Remove outliers"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# # normalize data, drop outliers beyond 4 times standard\n","# train_ = train_features.copy()\n","# drop_set = set()\n","# for col in GENES:\n","    \n","#     mean = train_[col].mean()\n","#     std = train_[col].std()\n","\n","#     std_r = mean + 4*std\n","#     std_l = mean - 4*std\n","\n","#     drop_set = drop_set | set(train_[col][(train_[col]>std_r) | (train_[col]<std_l)].index.values)\n","\n","# train_features = train_features.drop(drop_set).reset_index(drop=True)\n","# train_targets_scored = train_targets_scored.drop(drop_set).reset_index(drop=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["# PCA features + Existing features"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["# Because there are lots of genes expression and cols, some of them are highly correlated\n","# which means we can cut off some unnecessary features to make data cleaner\n","# GENES\n","n_comp = 50\n","\n","data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n","data2 = (PCA(n_components=n_comp, random_state=global_random_seed).fit_transform(data[GENES]))\n","# split the pca processed file back to train and test\n","train2 = data2[:train_features.shape[0]]\n","test2 = data2[-test_features.shape[0]:]\n","\n","# then use the pca sampled data to generate a new dataframe\n","train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n","test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n","# concat the PCA processed df back to original one\n","# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n","train_features = pd.concat((train_features, train2), axis=1)\n","test_features = pd.concat((test_features, test2), axis=1)"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["#CELLS\n","n_comp = 15\n","\n","data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n","data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n","\n","train2 = data2[:train_features.shape[0]]\n","test2 = data2[-test_features.shape[0]:]\n","\n","train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n","test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n","\n","# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n","train_features = pd.concat((train_features, train2), axis=1)\n","test_features = pd.concat((test_features, test2), axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["# feature Selection using Variance Encoding"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>cp_type</th>\n","      <th>cp_time</th>\n","      <th>cp_dose</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>...</th>\n","      <th>917</th>\n","      <th>918</th>\n","      <th>919</th>\n","      <th>920</th>\n","      <th>921</th>\n","      <th>922</th>\n","      <th>923</th>\n","      <th>924</th>\n","      <th>925</th>\n","      <th>926</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>1.0620</td>\n","      <td>0.5577</td>\n","      <td>-0.2479</td>\n","      <td>-0.6208</td>\n","      <td>-0.1944</td>\n","      <td>-1.0120</td>\n","      <td>...</td>\n","      <td>-0.450285</td>\n","      <td>-0.176778</td>\n","      <td>-1.262943</td>\n","      <td>0.219107</td>\n","      <td>-0.890670</td>\n","      <td>0.393604</td>\n","      <td>-0.703376</td>\n","      <td>-0.615139</td>\n","      <td>0.174407</td>\n","      <td>0.082941</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.0743</td>\n","      <td>0.4087</td>\n","      <td>0.2991</td>\n","      <td>0.0604</td>\n","      <td>1.0190</td>\n","      <td>0.5207</td>\n","      <td>...</td>\n","      <td>0.063234</td>\n","      <td>0.658824</td>\n","      <td>0.429385</td>\n","      <td>-0.226422</td>\n","      <td>0.271831</td>\n","      <td>0.863835</td>\n","      <td>0.003597</td>\n","      <td>0.669397</td>\n","      <td>0.447651</td>\n","      <td>1.207365</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>0.6280</td>\n","      <td>0.5817</td>\n","      <td>1.5540</td>\n","      <td>-0.0764</td>\n","      <td>-0.0323</td>\n","      <td>1.2390</td>\n","      <td>...</td>\n","      <td>-0.115802</td>\n","      <td>0.726273</td>\n","      <td>-0.212644</td>\n","      <td>-0.902482</td>\n","      <td>-0.118799</td>\n","      <td>-0.336548</td>\n","      <td>0.015536</td>\n","      <td>0.572233</td>\n","      <td>-0.261651</td>\n","      <td>-0.638141</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>trt_cp</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.5138</td>\n","      <td>-0.2491</td>\n","      <td>-0.2656</td>\n","      <td>0.5288</td>\n","      <td>4.0620</td>\n","      <td>-0.8095</td>\n","      <td>...</td>\n","      <td>0.590366</td>\n","      <td>0.698760</td>\n","      <td>0.050321</td>\n","      <td>-0.793301</td>\n","      <td>0.295411</td>\n","      <td>0.147857</td>\n","      <td>0.056161</td>\n","      <td>0.689218</td>\n","      <td>-1.433683</td>\n","      <td>1.323147</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>-0.3254</td>\n","      <td>-0.4009</td>\n","      <td>0.9700</td>\n","      <td>0.6919</td>\n","      <td>1.4180</td>\n","      <td>-0.8244</td>\n","      <td>...</td>\n","      <td>-0.000223</td>\n","      <td>-0.287454</td>\n","      <td>-0.110246</td>\n","      <td>-0.105291</td>\n","      <td>-0.396913</td>\n","      <td>0.090983</td>\n","      <td>-0.211590</td>\n","      <td>0.350304</td>\n","      <td>-0.326626</td>\n","      <td>-0.344389</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>23809</th>\n","      <td>id_fffb1ceed</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>0.1394</td>\n","      <td>-0.0636</td>\n","      <td>-0.1112</td>\n","      <td>-0.5080</td>\n","      <td>-0.4713</td>\n","      <td>0.7201</td>\n","      <td>...</td>\n","      <td>-0.492270</td>\n","      <td>0.802396</td>\n","      <td>0.332499</td>\n","      <td>-0.204876</td>\n","      <td>0.238577</td>\n","      <td>-0.483204</td>\n","      <td>0.585078</td>\n","      <td>0.173586</td>\n","      <td>-0.611718</td>\n","      <td>1.607084</td>\n","    </tr>\n","    <tr>\n","      <th>23810</th>\n","      <td>id_fffb70c0c</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>-1.3260</td>\n","      <td>0.3478</td>\n","      <td>-0.3743</td>\n","      <td>0.9905</td>\n","      <td>-0.7178</td>\n","      <td>0.6621</td>\n","      <td>...</td>\n","      <td>-1.364079</td>\n","      <td>-0.375444</td>\n","      <td>-1.433534</td>\n","      <td>-0.858483</td>\n","      <td>1.072457</td>\n","      <td>0.101450</td>\n","      <td>0.435098</td>\n","      <td>-0.219500</td>\n","      <td>0.377156</td>\n","      <td>0.555680</td>\n","    </tr>\n","    <tr>\n","      <th>23811</th>\n","      <td>id_fffc1c3f4</td>\n","      <td>ctl_vehicle</td>\n","      <td>48</td>\n","      <td>D2</td>\n","      <td>0.3942</td>\n","      <td>0.3756</td>\n","      <td>0.3109</td>\n","      <td>-0.7389</td>\n","      <td>0.5505</td>\n","      <td>-0.0159</td>\n","      <td>...</td>\n","      <td>-0.511130</td>\n","      <td>-0.035609</td>\n","      <td>-0.310135</td>\n","      <td>-0.166686</td>\n","      <td>-0.458886</td>\n","      <td>-0.003948</td>\n","      <td>0.292592</td>\n","      <td>0.331622</td>\n","      <td>-0.006669</td>\n","      <td>0.081750</td>\n","    </tr>\n","    <tr>\n","      <th>23812</th>\n","      <td>id_fffcb9e7c</td>\n","      <td>trt_cp</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>0.6660</td>\n","      <td>0.2324</td>\n","      <td>0.4392</td>\n","      <td>0.2044</td>\n","      <td>0.8531</td>\n","      <td>-0.0343</td>\n","      <td>...</td>\n","      <td>-1.129357</td>\n","      <td>0.020524</td>\n","      <td>-0.043233</td>\n","      <td>-0.440007</td>\n","      <td>0.302835</td>\n","      <td>0.776086</td>\n","      <td>-1.737516</td>\n","      <td>-0.531532</td>\n","      <td>-0.351892</td>\n","      <td>0.542268</td>\n","    </tr>\n","    <tr>\n","      <th>23813</th>\n","      <td>id_ffffdd77b</td>\n","      <td>trt_cp</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>-0.8598</td>\n","      <td>1.0240</td>\n","      <td>-0.1361</td>\n","      <td>0.7952</td>\n","      <td>-0.3611</td>\n","      <td>-3.6750</td>\n","      <td>...</td>\n","      <td>3.549881</td>\n","      <td>0.367554</td>\n","      <td>1.124858</td>\n","      <td>2.358549</td>\n","      <td>4.598061</td>\n","      <td>0.405195</td>\n","      <td>0.448931</td>\n","      <td>3.509945</td>\n","      <td>1.710206</td>\n","      <td>-2.434251</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23814 rows × 931 columns</p>\n","</div>"],"text/plain":["             sig_id      cp_type cp_time cp_dose       0       1       2   \n","0      id_000644bb2       trt_cp      24      D1  1.0620  0.5577 -0.2479  \\\n","1      id_000779bfc       trt_cp      72      D1  0.0743  0.4087  0.2991   \n","2      id_000a6266a       trt_cp      48      D1  0.6280  0.5817  1.5540   \n","3      id_0015fd391       trt_cp      48      D1 -0.5138 -0.2491 -0.2656   \n","4      id_001626bd3       trt_cp      72      D2 -0.3254 -0.4009  0.9700   \n","...             ...          ...     ...     ...     ...     ...     ...   \n","23809  id_fffb1ceed       trt_cp      24      D2  0.1394 -0.0636 -0.1112   \n","23810  id_fffb70c0c       trt_cp      24      D2 -1.3260  0.3478 -0.3743   \n","23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.3942  0.3756  0.3109   \n","23812  id_fffcb9e7c       trt_cp      24      D1  0.6660  0.2324  0.4392   \n","23813  id_ffffdd77b       trt_cp      72      D1 -0.8598  1.0240 -0.1361   \n","\n","            3       4       5  ...       917       918       919       920   \n","0     -0.6208 -0.1944 -1.0120  ... -0.450285 -0.176778 -1.262943  0.219107  \\\n","1      0.0604  1.0190  0.5207  ...  0.063234  0.658824  0.429385 -0.226422   \n","2     -0.0764 -0.0323  1.2390  ... -0.115802  0.726273 -0.212644 -0.902482   \n","3      0.5288  4.0620 -0.8095  ...  0.590366  0.698760  0.050321 -0.793301   \n","4      0.6919  1.4180 -0.8244  ... -0.000223 -0.287454 -0.110246 -0.105291   \n","...       ...     ...     ...  ...       ...       ...       ...       ...   \n","23809 -0.5080 -0.4713  0.7201  ... -0.492270  0.802396  0.332499 -0.204876   \n","23810  0.9905 -0.7178  0.6621  ... -1.364079 -0.375444 -1.433534 -0.858483   \n","23811 -0.7389  0.5505 -0.0159  ... -0.511130 -0.035609 -0.310135 -0.166686   \n","23812  0.2044  0.8531 -0.0343  ... -1.129357  0.020524 -0.043233 -0.440007   \n","23813  0.7952 -0.3611 -3.6750  ...  3.549881  0.367554  1.124858  2.358549   \n","\n","            921       922       923       924       925       926  \n","0     -0.890670  0.393604 -0.703376 -0.615139  0.174407  0.082941  \n","1      0.271831  0.863835  0.003597  0.669397  0.447651  1.207365  \n","2     -0.118799 -0.336548  0.015536  0.572233 -0.261651 -0.638141  \n","3      0.295411  0.147857  0.056161  0.689218 -1.433683  1.323147  \n","4     -0.396913  0.090983 -0.211590  0.350304 -0.326626 -0.344389  \n","...         ...       ...       ...       ...       ...       ...  \n","23809  0.238577 -0.483204  0.585078  0.173586 -0.611718  1.607084  \n","23810  1.072457  0.101450  0.435098 -0.219500  0.377156  0.555680  \n","23811 -0.458886 -0.003948  0.292592  0.331622 -0.006669  0.081750  \n","23812  0.302835  0.776086 -1.737516 -0.531532 -0.351892  0.542268  \n","23813  4.598061  0.405195  0.448931  3.509945  1.710206 -2.434251  \n","\n","[23814 rows x 931 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_selection import VarianceThreshold\n","# use variance threshold to collect columns\n","# remove low variance columns and features\n","var_thresh = VarianceThreshold(threshold=0.5)\n","# data = train_features.append(test_features)\n","data = pd.concat([train_features, test_features], axis = 0)\n","data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n","\n","# \n","train_features_transformed = data_transformed[ : train_features.shape[0]]\n","test_features_transformed = data_transformed[-test_features.shape[0] : ]\n","\n","\n","train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n","                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n","\n","train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n","\n","\n","test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n","                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n","\n","test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n","\n","train_features"]},{"cell_type":"markdown","metadata":{},"source":["# Binning"]},{"cell_type":"code","execution_count":9,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# for col in GENES:\n","#     train.loc[:, f'{col}_bin'] = pd.cut(train[col], bins=3, labels=False)\n","#     test.loc[:, f'{col}_bin'] = pd.cut(test[col], bins=3, labels=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Distribution plots"]},{"cell_type":"code","execution_count":10,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# plt.figure(figsize=(16,16))\n","# sns.set_style(\"whitegrid\")\n","\n","# gene_choice = np.random.choice(len(GENES), 16)\n","# for i, col in enumerate(gene_choice):\n","#     plt.subplot(4, 4, i+1)\n","#     plt.hist(train_features.loc[:, GENES[col]],bins=100, color='orange')\n","#     plt.title(GENES[col])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["train = train_features.merge(train_targets_scored, on='sig_id')\n","train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n","test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n","\n","train.drop(columns=['cp_type'], axis = 1, inplace=True)\n","test.drop(columns=['cp_type'], axis = 1, inplace=True)\n","\n","target = train[train_targets_scored.columns]"]},{"cell_type":"markdown","metadata":{},"source":["# CV folds"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sig_id</th>\n","      <th>cp_time</th>\n","      <th>cp_dose</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>...</th>\n","      <th>trpv_agonist</th>\n","      <th>trpv_antagonist</th>\n","      <th>tubulin_inhibitor</th>\n","      <th>tyrosine_kinase_inhibitor</th>\n","      <th>ubiquitin_specific_protease_inhibitor</th>\n","      <th>vegfr_inhibitor</th>\n","      <th>vitamin_b</th>\n","      <th>vitamin_d_receptor_agonist</th>\n","      <th>wnt_inhibitor</th>\n","      <th>kfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_000644bb2</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>1.0620</td>\n","      <td>0.5577</td>\n","      <td>-0.2479</td>\n","      <td>-0.6208</td>\n","      <td>-0.1944</td>\n","      <td>-1.0120</td>\n","      <td>-1.0220</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_000779bfc</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.0743</td>\n","      <td>0.4087</td>\n","      <td>0.2991</td>\n","      <td>0.0604</td>\n","      <td>1.0190</td>\n","      <td>0.5207</td>\n","      <td>0.2341</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_000a6266a</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>0.6280</td>\n","      <td>0.5817</td>\n","      <td>1.5540</td>\n","      <td>-0.0764</td>\n","      <td>-0.0323</td>\n","      <td>1.2390</td>\n","      <td>0.1715</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_0015fd391</td>\n","      <td>48</td>\n","      <td>D1</td>\n","      <td>-0.5138</td>\n","      <td>-0.2491</td>\n","      <td>-0.2656</td>\n","      <td>0.5288</td>\n","      <td>4.0620</td>\n","      <td>-0.8095</td>\n","      <td>-1.9590</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_001626bd3</td>\n","      <td>72</td>\n","      <td>D2</td>\n","      <td>-0.3254</td>\n","      <td>-0.4009</td>\n","      <td>0.9700</td>\n","      <td>0.6919</td>\n","      <td>1.4180</td>\n","      <td>-0.8244</td>\n","      <td>-0.2800</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21943</th>\n","      <td>id_fff8c2444</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>0.1608</td>\n","      <td>-1.0500</td>\n","      <td>0.2551</td>\n","      <td>-0.2239</td>\n","      <td>-0.2431</td>\n","      <td>0.4256</td>\n","      <td>-0.1166</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21944</th>\n","      <td>id_fffb1ceed</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>0.1394</td>\n","      <td>-0.0636</td>\n","      <td>-0.1112</td>\n","      <td>-0.5080</td>\n","      <td>-0.4713</td>\n","      <td>0.7201</td>\n","      <td>0.5773</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>21945</th>\n","      <td>id_fffb70c0c</td>\n","      <td>24</td>\n","      <td>D2</td>\n","      <td>-1.3260</td>\n","      <td>0.3478</td>\n","      <td>-0.3743</td>\n","      <td>0.9905</td>\n","      <td>-0.7178</td>\n","      <td>0.6621</td>\n","      <td>-0.2252</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21946</th>\n","      <td>id_fffcb9e7c</td>\n","      <td>24</td>\n","      <td>D1</td>\n","      <td>0.6660</td>\n","      <td>0.2324</td>\n","      <td>0.4392</td>\n","      <td>0.2044</td>\n","      <td>0.8531</td>\n","      <td>-0.0343</td>\n","      <td>0.0323</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21947</th>\n","      <td>id_ffffdd77b</td>\n","      <td>72</td>\n","      <td>D1</td>\n","      <td>-0.8598</td>\n","      <td>1.0240</td>\n","      <td>-0.1361</td>\n","      <td>0.7952</td>\n","      <td>-0.3611</td>\n","      <td>-3.6750</td>\n","      <td>-1.2420</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21948 rows × 1137 columns</p>\n","</div>"],"text/plain":["             sig_id cp_time cp_dose       0       1       2       3       4   \n","0      id_000644bb2      24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944  \\\n","1      id_000779bfc      72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n","2      id_000a6266a      48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323   \n","3      id_0015fd391      48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620   \n","4      id_001626bd3      72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180   \n","...             ...     ...     ...     ...     ...     ...     ...     ...   \n","21943  id_fff8c2444      72      D1  0.1608 -1.0500  0.2551 -0.2239 -0.2431   \n","21944  id_fffb1ceed      24      D2  0.1394 -0.0636 -0.1112 -0.5080 -0.4713   \n","21945  id_fffb70c0c      24      D2 -1.3260  0.3478 -0.3743  0.9905 -0.7178   \n","21946  id_fffcb9e7c      24      D1  0.6660  0.2324  0.4392  0.2044  0.8531   \n","21947  id_ffffdd77b      72      D1 -0.8598  1.0240 -0.1361  0.7952 -0.3611   \n","\n","            5       6  ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor   \n","0     -1.0120 -1.0220  ...             0                0                  0  \\\n","1      0.5207  0.2341  ...             0                0                  0   \n","2      1.2390  0.1715  ...             0                0                  0   \n","3     -0.8095 -1.9590  ...             0                0                  0   \n","4     -0.8244 -0.2800  ...             0                0                  0   \n","...       ...     ...  ...           ...              ...                ...   \n","21943  0.4256 -0.1166  ...             0                0                  0   \n","21944  0.7201  0.5773  ...             0                0                  0   \n","21945  0.6621 -0.2252  ...             0                0                  0   \n","21946 -0.0343  0.0323  ...             0                0                  0   \n","21947 -3.6750 -1.2420  ...             0                0                  0   \n","\n","       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor   \n","0                              0                                      0  \\\n","1                              0                                      0   \n","2                              0                                      0   \n","3                              0                                      0   \n","4                              0                                      0   \n","...                          ...                                    ...   \n","21943                          0                                      0   \n","21944                          0                                      0   \n","21945                          0                                      0   \n","21946                          0                                      0   \n","21947                          0                                      0   \n","\n","       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor   \n","0                    0          0                           0              0  \\\n","1                    0          0                           0              0   \n","2                    0          0                           0              0   \n","3                    0          0                           0              0   \n","4                    0          0                           0              0   \n","...                ...        ...                         ...            ...   \n","21943                0          0                           0              0   \n","21944                0          0                           0              0   \n","21945                0          0                           0              0   \n","21946                0          0                           0              0   \n","21947                0          0                           0              0   \n","\n","       kfold  \n","0          0  \n","1          2  \n","2          1  \n","3          2  \n","4          2  \n","...      ...  \n","21943      0  \n","21944      4  \n","21945      0  \n","21946      1  \n","21947      2  \n","\n","[21948 rows x 1137 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["folds = train.copy()\n","\n","mskf = MultilabelStratifiedKFold(n_splits=5)\n","\n","for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n","    folds.loc[v_idx, 'kfold'] = int(f)\n","\n","folds['kfold'] = folds['kfold'].astype(int)\n","folds"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(21948, 1136)\n","(21948, 1137)\n","(3624, 930)\n","(21948, 207)\n","(3982, 207)\n"]}],"source":["print(train.shape)\n","print(folds.shape)\n","print(test.shape)\n","print(target.shape)\n","print(sample_submission.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Classes"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["class MoADataset:\n","    def __init__(self, features, targets):\n","        self.features = features\n","        self.targets = targets\n","        \n","    def __len__(self):\n","        return (self.features.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        dct = {\n","            'x' : torch.tensor(self.features[idx, :].astype(np.float32), dtype=torch.float),\n","            'y' : torch.tensor(self.targets[idx, :].astype(np.float32), dtype=torch.float)            \n","        }\n","        return dct\n","    \n","class TestDataset:\n","    def __init__(self, features):\n","        self.features = features\n","        \n","    def __len__(self):\n","        return (self.features.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        dct = {\n","            'x' : torch.tensor(self.features[idx, :].astype(np.float32), dtype=torch.float)\n","        }\n","        return dct\n","    "]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n","    model.train()\n","    final_loss = 0\n","    \n","    for data in dataloader:\n","        optimizer.zero_grad()\n","        inputs, targets = data['x'].to(device), data['y'].to(device)\n","#         print(inputs.shape)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        final_loss += loss.item()\n","        \n","    final_loss /= len(dataloader)\n","    \n","    return final_loss\n","\n","\n","def valid_fn(model, loss_fn, dataloader, device):\n","    model.eval()\n","    final_loss = 0\n","    valid_preds = []\n","    \n","    for data in dataloader:\n","        inputs, targets = data['x'].to(device), data['y'].to(device)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, targets)\n","        \n","        final_loss += loss.item()\n","        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n","        \n","    final_loss /= len(dataloader)\n","    valid_preds = np.concatenate(valid_preds)\n","    \n","    return final_loss, valid_preds\n","\n","def inference_fn(model, dataloader, device):\n","    model.eval()\n","    preds = []\n","    \n","    for data in dataloader:\n","        inputs = data['x'].to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(inputs)\n","        \n","        preds.append(outputs.sigmoid().detach().cpu().numpy())\n","        \n","    preds = np.concatenate(preds)\n","    \n","    return preds\n","   \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["# load model\n","model_dict = {\n","    'CNN':CNN,\n","    'DNN':DNN,\n","    'AdvDNN':AdvDNN\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing steps"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["def process_data(data):\n","    \n","    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n","#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n","#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n","\n","# --------------------- Normalize ---------------------\n","#     for col in GENES:\n","#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n","    \n","#     for col in CELLS:\n","#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n","    \n","#--------------------- Removing Skewness ---------------------\n","#     for col in GENES + CELLS:\n","#         if(abs(data[col].skew()) > 0.75):\n","            \n","#             if(data[col].skew() < 0): # neg-skewness\n","#                 data[col] = data[col].max() - data[col] + 1\n","#                 data[col] = np.sqrt(data[col])\n","            \n","#             else:\n","#                 data[col] = np.sqrt(data[col])\n","    \n","    return data"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["932"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n","feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n","len(feature_cols)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["# HyperParameters\n","\n","DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n","EPOCHS = 25\n","BATCH_SIZE = 128\n","LEARNING_RATE = 1e-3\n","WEIGHT_DECAY = 1e-5\n","NFOLDS = 5\n","EARLY_STOPPING_STEPS = 10\n","EARLY_STOP = False\n","\n","num_features=len(feature_cols)\n","num_targets=len(target_cols)\n","hidden_size=1024\n","\n","target_model = 'CNN'\n"]},{"cell_type":"markdown","metadata":{},"source":["# Single fold training"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["def run_training(fold, seed, model_name):\n","    \n","    seed_everything(seed)\n","    \n","    train = process_data(folds)\n","    test_ = process_data(test)\n","    \n","    trn_idx = train[train['kfold'] != fold].index\n","    val_idx = train[train['kfold'] == fold].index\n","    \n","    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n","    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n","    \n","    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n","    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n","    \n","    train_dataset = MoADataset(x_train, y_train)\n","    valid_dataset = MoADataset(x_valid, y_valid)\n","    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","\n","    model = model_dict[model_name](\n","        num_features=num_features,\n","        num_targets=num_targets,\n","        hidden_size=hidden_size,\n","    )\n","\n","\n","    \n","    model.to(DEVICE)\n","    \n","    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n","                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n","    \n","    loss_fn = nn.BCEWithLogitsLoss()\n","    \n","    early_stopping_steps = EARLY_STOPPING_STEPS\n","    early_step = 0\n","    \n","    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n","    best_loss = np.inf\n","    \n","    for epoch in range(EPOCHS):\n","        \n","        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n","        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n","        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n","        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n","        \n","        if valid_loss < best_loss:\n","            \n","            best_loss = valid_loss\n","            oof[val_idx] = valid_preds\n","            torch.save(model.state_dict(), f\"{model_name}_FOLD{fold}_.pth\")\n","        \n","        elif(EARLY_STOP == True):\n","            \n","            early_step += 1\n","            if (early_step >= early_stopping_steps):\n","                break\n","            \n","    \n","    #--------------------- PREDICTION---------------------\n","    x_test = test_[feature_cols].values\n","    testdataset = TestDataset(x_test)\n","    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","\n","    model = model_dict[model_name](\n","        num_features=num_features,\n","        num_targets=num_targets,\n","        hidden_size=hidden_size,\n","    )\n","    \n","    model.load_state_dict(torch.load(f\"{model_name}_FOLD{fold}_.pth\"))\n","\n","    model.to(DEVICE)\n","    \n","    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n","    predictions = inference_fn(model, testloader, DEVICE)\n","    \n","    return oof, predictions\n"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["def run_k_fold(NFOLDS, seed):\n","    oof = np.zeros((len(train), len(target_cols)))\n","    predictions = np.zeros((len(test), len(target_cols)))\n","    \n","    for fold in range(NFOLDS):\n","        oof_, pred_ = run_training(fold, seed, target_model)\n","        \n","        predictions += pred_ / NFOLDS\n","        oof += oof_\n","        \n","    return oof, predictions"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["FOLD: 0, EPOCH: 0, train_loss: 0.5339408829214348\n","FOLD: 0, EPOCH: 0, valid_loss: 0.04475398351039205\n","FOLD: 0, EPOCH: 1, train_loss: 0.02386083421499833\n","FOLD: 0, EPOCH: 1, valid_loss: 0.022790928876825742\n","FOLD: 0, EPOCH: 2, train_loss: 0.018938364380079765\n","FOLD: 0, EPOCH: 2, valid_loss: 0.01892631910741329\n","FOLD: 0, EPOCH: 3, train_loss: 0.01848754563463339\n","FOLD: 0, EPOCH: 3, valid_loss: 0.017802271007427147\n","FOLD: 0, EPOCH: 4, train_loss: 0.01773979903563209\n","FOLD: 0, EPOCH: 4, valid_loss: 0.017700715841991562\n","FOLD: 0, EPOCH: 5, train_loss: 0.017567242252761902\n","FOLD: 0, EPOCH: 5, valid_loss: 0.017612303820039546\n","FOLD: 0, EPOCH: 6, train_loss: 0.017374467482601387\n","FOLD: 0, EPOCH: 6, valid_loss: 0.018091507495513984\n","FOLD: 0, EPOCH: 7, train_loss: 0.017292977978839823\n","FOLD: 0, EPOCH: 7, valid_loss: 0.017161002302808422\n","FOLD: 0, EPOCH: 8, train_loss: 0.01728276260521101\n","FOLD: 0, EPOCH: 8, valid_loss: 0.017147762940398284\n","FOLD: 0, EPOCH: 9, train_loss: 0.01719597743932104\n","FOLD: 0, EPOCH: 9, valid_loss: 0.017317170995686734\n","FOLD: 0, EPOCH: 10, train_loss: 0.0171091026302589\n","FOLD: 0, EPOCH: 10, valid_loss: 0.017276941958282676\n","FOLD: 0, EPOCH: 11, train_loss: 0.017018200262733128\n","FOLD: 0, EPOCH: 11, valid_loss: 0.017297169512936045\n","FOLD: 0, EPOCH: 12, train_loss: 0.016854486671154915\n","FOLD: 0, EPOCH: 12, valid_loss: 0.016914417834154198\n","FOLD: 0, EPOCH: 13, train_loss: 0.016731437936803137\n","FOLD: 0, EPOCH: 13, valid_loss: 0.01670310491962092\n","FOLD: 0, EPOCH: 14, train_loss: 0.016624850322208975\n","FOLD: 0, EPOCH: 14, valid_loss: 0.01659816237432616\n","FOLD: 0, EPOCH: 15, train_loss: 0.016390345592483663\n","FOLD: 0, EPOCH: 15, valid_loss: 0.016693285267267908\n","FOLD: 0, EPOCH: 16, train_loss: 0.016204042812350435\n","FOLD: 0, EPOCH: 16, valid_loss: 0.016520422670458043\n","FOLD: 0, EPOCH: 17, train_loss: 0.01598876070879076\n","FOLD: 0, EPOCH: 17, valid_loss: 0.016353631684822695\n","FOLD: 0, EPOCH: 18, train_loss: 0.015605230080098778\n","FOLD: 0, EPOCH: 18, valid_loss: 0.016142787065889154\n","FOLD: 0, EPOCH: 19, train_loss: 0.015315617414434319\n","FOLD: 0, EPOCH: 19, valid_loss: 0.01600995452276298\n","FOLD: 0, EPOCH: 20, train_loss: 0.014752278090927048\n","FOLD: 0, EPOCH: 20, valid_loss: 0.01580793583499534\n","FOLD: 0, EPOCH: 21, train_loss: 0.014382426390775305\n","FOLD: 0, EPOCH: 21, valid_loss: 0.015717267032180515\n","FOLD: 0, EPOCH: 22, train_loss: 0.013999023393768332\n","FOLD: 0, EPOCH: 22, valid_loss: 0.015659731945821216\n","FOLD: 0, EPOCH: 23, train_loss: 0.013574257654988247\n","FOLD: 0, EPOCH: 23, valid_loss: 0.015665869255151066\n","FOLD: 0, EPOCH: 24, train_loss: 0.013401223049647566\n","FOLD: 0, EPOCH: 24, valid_loss: 0.015666223290775504\n","FOLD: 1, EPOCH: 0, train_loss: 0.531676044633639\n","FOLD: 1, EPOCH: 0, valid_loss: 0.2088813473071371\n","FOLD: 1, EPOCH: 1, train_loss: 0.02374278161458779\n","FOLD: 1, EPOCH: 1, valid_loss: 0.019971787929534912\n","FOLD: 1, EPOCH: 2, train_loss: 0.019153322268655334\n","FOLD: 1, EPOCH: 2, valid_loss: 0.018612621618168696\n","FOLD: 1, EPOCH: 3, train_loss: 0.01826491889854272\n","FOLD: 1, EPOCH: 3, valid_loss: 0.017849342258913176\n","FOLD: 1, EPOCH: 4, train_loss: 0.017843596765474565\n","FOLD: 1, EPOCH: 4, valid_loss: 0.018727566195385795\n","FOLD: 1, EPOCH: 5, train_loss: 0.01765701085652994\n","FOLD: 1, EPOCH: 5, valid_loss: 0.017612767751727786\n","FOLD: 1, EPOCH: 6, train_loss: 0.017505122557876333\n","FOLD: 1, EPOCH: 6, valid_loss: 0.017590396319116866\n","FOLD: 1, EPOCH: 7, train_loss: 0.017264157040989485\n","FOLD: 1, EPOCH: 7, valid_loss: 0.01745279242417642\n","FOLD: 1, EPOCH: 8, train_loss: 0.017285418581973383\n","FOLD: 1, EPOCH: 8, valid_loss: 0.017417579969125133\n","FOLD: 1, EPOCH: 9, train_loss: 0.017348984411607187\n","FOLD: 1, EPOCH: 9, valid_loss: 0.017408862550343785\n","FOLD: 1, EPOCH: 10, train_loss: 0.01714788695824319\n","FOLD: 1, EPOCH: 10, valid_loss: 0.01699399873614311\n","FOLD: 1, EPOCH: 11, train_loss: 0.017001526308772358\n","FOLD: 1, EPOCH: 11, valid_loss: 0.017099410268877235\n","FOLD: 1, EPOCH: 12, train_loss: 0.016875261704073004\n","FOLD: 1, EPOCH: 12, valid_loss: 0.0168673395046166\n","FOLD: 1, EPOCH: 13, train_loss: 0.01674099264504469\n","FOLD: 1, EPOCH: 13, valid_loss: 0.016869390356753555\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(test), \u001b[38;5;28mlen\u001b[39m(target_cols)))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m SEED:\n\u001b[0;32m----> 9\u001b[0m     oof_, predictions_ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_k_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNFOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     oof \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m oof_ \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(SEED)\n\u001b[1;32m     11\u001b[0m     predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m predictions_ \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(SEED)\n","Cell \u001b[0;32mIn[21], line 6\u001b[0m, in \u001b[0;36mrun_k_fold\u001b[0;34m(NFOLDS, seed)\u001b[0m\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(test), \u001b[38;5;28mlen\u001b[39m(target_cols)))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NFOLDS):\n\u001b[0;32m----> 6\u001b[0m     oof_, pred_ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pred_ \u001b[38;5;241m/\u001b[39m NFOLDS\n\u001b[1;32m      9\u001b[0m     oof \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m oof_\n","Cell \u001b[0;32mIn[20], line 47\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(fold, seed, model_name)\u001b[0m\n\u001b[1;32m     43\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 47\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOLD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, EPOCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     valid_loss, valid_preds \u001b[38;5;241m=\u001b[39m valid_fn(model, loss_fn, validloader, DEVICE)\n","Cell \u001b[0;32mIn[15], line 5\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, optimizer, scheduler, loss_fn, dataloader, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m final_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[14], line 11\u001b[0m, in \u001b[0;36mMoADataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     10\u001b[0m     dct \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m : torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat),\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m : torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[idx, :]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)            \n\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dct\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Averaging on multiple SEEDS\n","\n","SEED = [0, 1, 2, 3 ,4, 5]\n","oof = np.zeros((len(train), len(target_cols)))\n","predictions = np.zeros((len(test), len(target_cols)))\n","\n","for seed in SEED:\n","    \n","    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n","    oof += oof_ / len(SEED)\n","    predictions += predictions_ / len(SEED)\n","\n","train[target_cols] = oof\n","test[target_cols] = predictions\n"]},{"cell_type":"code","execution_count":58,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# test['atp-sensitive_potassium_channel_antagonist'] = 0.0\n","# test['erbb2_inhibitor'] = 0.0\n","\n","# train['atp-sensitive_potassium_channel_antagonist'] = 0.0\n","# train['erbb2_inhibitor'] = 0.0"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CV log_loss:  0.11846599142321435\n"]}],"source":["valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n","\n","\n","y_true = train_targets_scored[target_cols].values\n","y_pred = valid_results[target_cols].values\n","\n","score = 0\n","for i in range(len(target_cols)):\n","    score_ = log_loss(y_true[:, i], y_pred[:, i])\n","    score += score_ / target.shape[1]\n","    \n","print(\"CV log_loss: \", score)"]},{"cell_type":"code","execution_count":49,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CV log_loss:  0.1184696218779818\n"]}],"source":["valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n","\n","\n","y_true = train_targets_scored[target_cols].values\n","y_pred = valid_results[target_cols].values\n","\n","score = 0\n","for i in range(len(target_cols)):\n","    score_ = log_loss(y_true[:, i], y_pred[:, i])\n","    score += score_ / target.shape[1]\n","    \n","print(\"CV log_loss: \", score)"]},{"cell_type":"code","execution_count":67,"metadata":{"trusted":true},"outputs":[],"source":["sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n","sub.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n"]}],"source":["# import torch\n","# import torch.nn as nn\n","# import torch.onnx as onnx\n","\n","# # 定义模型\n","# class Model(nn.Module):\n","#     def __init__(self, num_features, num_targets, hidden_size):\n","#         super(Model, self).__init__()\n","#         self.batch_norm1 = nn.BatchNorm1d(num_features)\n","#         self.dropout1 = nn.Dropout(0.2)\n","#         self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n","\n","#         self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n","#         self.dropout2 = nn.Dropout(0.5)\n","#         self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n","\n","#         self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n","#         self.dropout3 = nn.Dropout(0.5)\n","#         self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n","\n","#     def forward(self, x):\n","#         x = self.batch_norm1(x)\n","#         x = self.dropout1(x)\n","#         x = torch.relu(self.dense1(x))\n","\n","#         x = self.batch_norm2(x)\n","#         x = self.dropout2(x)\n","#         x = torch.relu(self.dense2(x))\n","\n","#         x = self.batch_norm3(x)\n","#         x = self.dropout3(x)\n","#         x = self.dense3(x)\n","\n","#         return x\n","\n","# # 创建模型实例\n","# model = Model(num_features=num_features, num_targets=num_targets, hidden_size=hidden_size)\n","\n","# # 创建一个示例输入\n","# x = torch.randn(21948, num_features)\n","\n","# # 导出模型为ONNX格式\n","# torch.onnx.export(model,  # 导出的模型\n","#                   x,  # 输入数据\n","#                   \"model.onnx\",  # 导出的文件路径\n","#                   )  # 显示详细信息\n"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting onnx\n","  Downloading onnx-1.14.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.20.2 in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (4.23.0)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (4.5.0)\n","Requirement already satisfied: numpy in /home/longc/anaconda3/envs/ann/lib/python3.8/site-packages (from onnx) (1.24.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.14.0\n"]}],"source":["!pip install onnx"]},{"cell_type":"markdown","metadata":{},"source":["## Things that can improve your CV even further:\n","1. Increasing SEEDS\n","2. Feature Selection over GENES/CELLS columns\n","3. Model Hyperparameter Tuning\n","4. Removing Skewness from GENES/CELLS columns [Comment below if it helps]\n","5. PCA........................................[Comment below if it helps]\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.16 ('ann')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"c5aa68934cf576379d06986a60942effae75d2e29c28cc454c328232c9ed20eb"}}},"nbformat":4,"nbformat_minor":4}
